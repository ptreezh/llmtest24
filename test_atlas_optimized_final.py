#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•atlasæ¨¡å‹çš„æœ€ç»ˆä¼˜åŒ–é…ç½®ï¼š
- ç³»ç»Ÿæç¤ºè¯é™åˆ¶åœ¨80å­—ç¬¦ä»¥å†…
- æ€»ç»“å†…å®¹ä¸¥æ ¼é™åˆ¶åœ¨150å­—ç¬¦ä»¥å†…
- æ€»æç¤ºè¯ä¸¥æ ¼é™åˆ¶åœ¨360å­—ç¬¦ä»¥å†…
- æ¯2000 tokensæ€»ç»“ä¸€æ¬¡
"""

def get_prompt(prompt_type: str, context: dict = {}, model: str = "") -> str:
    """å¤åˆ¶TestLLM.pyä¸­çš„get_promptå‡½æ•°è¿›è¡Œæµ‹è¯•"""
    # é’ˆå¯¹atlas/intersync-gemmaæ¨¡å‹çš„ç²¾ç®€æç¤ºè¯ï¼ˆæ€»é•¿åº¦<360å­—ç¬¦ï¼‰
    # ç³»ç»Ÿæç¤ºè¯(80) + ç”¨æˆ·æç¤ºè¯(<280) = 360å­—ç¬¦ï¼Œæ€»ç»“å†…å®¹ä¸¥æ ¼é™åˆ¶åœ¨150å­—ç¬¦
    if "atlas/intersync-gemma" in model:
        if prompt_type == "intermediate":
            if context.get('summary_so_far', '').strip() and context.get('summary_so_far', '').strip() != 'None':
                # åŒ…å«ä»»åŠ¡+æ¦‚æ‹¬+æ–°å†…å®¹ï¼Œæ€»è®¡<280å­—ç¬¦ï¼ˆç³»ç»Ÿæç¤ºè¯80å­—ç¬¦ï¼‰
                task = "Find killer:"  # 12å­—ç¬¦ä»»åŠ¡è¯´æ˜
                summary = context['summary_so_far'][:150]  # 150å­—ç¬¦æ¦‚æ‹¬ï¼ˆä¸¥æ ¼é™åˆ¶ï¼Œé¿å…æˆªæ–­ï¼‰
                new_content = context['new_dialogue_chunk'][:100]  # 100å­—ç¬¦æ–°å†…å®¹
                return f"{task}\nEvidence: {summary}\nNew: {new_content}\nUpdate:"
            else:
                # åˆå§‹æç¤ºè¯ï¼šä»»åŠ¡+å†…å®¹
                task = "Find killer:"  # 12å­—ç¬¦ä»»åŠ¡è¯´æ˜
                content = context['new_dialogue_chunk'][:250]  # 250å­—ç¬¦å†…å®¹
                return f"{task}\nDialogue: {content}\nSummary:"
        elif prompt_type == "final":
            # æœ€ç»ˆæ¨ç†ï¼šä»»åŠ¡+æ¦‚æ‹¬
            task = "Find killer:"  # 12å­—ç¬¦ä»»åŠ¡è¯´æ˜
            facts = context.get('summary_so_far', '')[:250]  # 250å­—ç¬¦äº‹å®
            return f"{task}\nEvidence: {facts}\nAnswer:"
    
    return "Standard prompt for other models"

def test_final_optimization():
    """æµ‹è¯•æœ€ç»ˆä¼˜åŒ–é…ç½®"""
    print("ğŸ§ª Testing Atlas Model Final Optimization")
    print("="*50)
    
    model = "atlas/intersync-gemma-7b-instruct-function-calling:latest"
    system_prompt = "Detective. Analyze murder case. Summarize key evidence concisely."
    
    print(f"System prompt: '{system_prompt}' ({len(system_prompt)} chars)")
    print(f"System prompt limit: 80 chars - {'âœ… PASS' if len(system_prompt) <= 80 else 'âŒ FAIL'}")
    
    # æµ‹è¯•åœºæ™¯1ï¼šåˆå§‹æ‘˜è¦ï¼ˆ2000 tokensåˆ†æ®µï¼‰
    test_dialogue = "Aï¼šæ˜¨æ™šæˆ‘å¬åˆ°äº†å¥‡æ€ªçš„å£°éŸ³ï¼Œå¥½åƒæ˜¯ä»æ£®æ—é‚£è¾¹ä¼ æ¥çš„ï¼Œå£°éŸ³å¾ˆè§„å¾‹ï¼Œä¸åƒæ˜¯é‡å…½å‘å‡ºçš„ã€‚Bï¼šæˆ‘ä¹Ÿå¬åˆ°äº†ï¼Œè€Œä¸”æˆ‘è¿˜çœ‹åˆ°äº†ä¸€ä¸ªé»‘å½±åœ¨è€æ©¡æ ‘é™„è¿‘ç§»åŠ¨ï¼Œé‚£ä¸ªäººåŠ¨ä½œå¾ˆå¿«ã€‚Cï¼šè¿™ç¡®å®å¾ˆå¥‡æ€ªï¼Œä¼šä¸ä¼šæ˜¯æœ‰äººåœ¨é‚£é‡Œåšä»€ä¹ˆåäº‹ï¼Ÿæ˜¨æ™šé‚£ä¹ˆæ™šäº†è¿˜æœ‰äººåœ¨å¤–é¢ç¡®å®ä¸æ­£å¸¸ã€‚Dï¼šæˆ‘è§‰å¾—å¯èƒ½æ˜¯ä¼æœ¨å·¥åœ¨å·¥ä½œï¼Œä½†è¿™ä¹ˆæ™šäº†è¿˜å·¥ä½œç¡®å®å¾ˆå¥‡æ€ªã€‚"
    
    context1 = {
        "new_dialogue_chunk": test_dialogue
    }
    
    prompt1 = get_prompt("intermediate", context1, model)
    total1 = len(system_prompt) + len(prompt1)
    
    print(f"\n--- åœºæ™¯1ï¼šåˆå§‹æ‘˜è¦ï¼ˆ2000 tokensåˆ†æ®µï¼‰ ---")
    print(f"User prompt: '{prompt1}' ({len(prompt1)} chars)")
    print(f"Total length: {total1} chars")
    print(f"âœ… Within 360 limit: {total1 <= 360}")
    
    # æµ‹è¯•åœºæ™¯2ï¼šæ›´æ–°æ‘˜è¦ï¼ˆæ¨¡æ‹Ÿ150å­—ç¬¦ä»¥å†…çš„æ‘˜è¦ï¼‰
    previous_summary = "æ˜¨æ™šå¬åˆ°è§„å¾‹å£°éŸ³æ¥è‡ªæ£®æ—ï¼Œçœ‹åˆ°é»‘å½±åœ¨è€æ©¡æ ‘é™„è¿‘ç§»åŠ¨ï¼Œæ€€ç–‘æœ‰äººåšåäº‹ã€‚å¯èƒ½æ˜¯ä¼æœ¨å·¥ä½†æ—¶é—´ä¸æ­£å¸¸ã€‚éœ€è¦è¿›ä¸€æ­¥è°ƒæŸ¥ã€‚"  # çº¦70å­—ç¬¦
    
    context2 = {
        "summary_so_far": previous_summary,
        "new_dialogue_chunk": test_dialogue
    }
    
    prompt2 = get_prompt("intermediate", context2, model)
    total2 = len(system_prompt) + len(prompt2)
    
    print(f"\n--- åœºæ™¯2ï¼šæ›´æ–°æ‘˜è¦ï¼ˆ150å­—ç¬¦é™åˆ¶ï¼‰ ---")
    print(f"Previous summary: '{previous_summary}' ({len(previous_summary)} chars)")
    print(f"User prompt: '{prompt2}' ({len(prompt2)} chars)")
    print(f"Total length: {total2} chars")
    print(f"âœ… Within 360 limit: {total2 <= 360}")
    print(f"âœ… Summary within 150 limit: {len(previous_summary) <= 150}")
    
    # æµ‹è¯•åœºæ™¯3ï¼šæœ€ç»ˆæ¨ç†
    final_summary = "ç»è¿‡å¤šè½®åˆ†æï¼šæ˜¨æ™šæ£®æ—ä¼ æ¥è§„å¾‹å£°éŸ³ï¼Œè€æ©¡æ ‘é™„è¿‘å‘ç°é»‘å½±ç§»åŠ¨ã€‚å¼ ä¸‰ä¸¢å¤±æ–§å¤´ï¼Œåœ°é¢æœ‰å¤§é´å­è„šå°ã€‚é»‘å½±èº«é«˜ä¸€ç±³å…«å·¦å³ã€‚æå››æ·±å¤œå¤–å‡ºï¼Œä¸å¼ ä¸‰æœ‰çŸ›ç›¾ï¼Œèº«é«˜ç¬¦åˆã€‚"  # çº¦90å­—ç¬¦
    
    context3 = {
        "summary_so_far": final_summary
    }
    
    prompt3 = get_prompt("final", context3, model)
    total3 = len(system_prompt) + len(prompt3)
    
    print(f"\n--- åœºæ™¯3ï¼šæœ€ç»ˆæ¨ç† ---")
    print(f"Final summary: '{final_summary}' ({len(final_summary)} chars)")
    print(f"User prompt: '{prompt3}' ({len(prompt3)} chars)")
    print(f"Total length: {total3} chars")
    print(f"âœ… Within 360 limit: {total3 <= 360}")
    print(f"âœ… Summary within 150 limit: {len(final_summary) <= 150}")
    
    # æµ‹è¯•åœºæ™¯4ï¼šæé™æƒ…å†µï¼ˆ150å­—ç¬¦æ‘˜è¦ï¼‰
    max_summary = "ç»è¿‡å¤šè½®åˆ†æï¼šæ˜¨æ™šæ£®æ—ä¼ æ¥è§„å¾‹å£°éŸ³ï¼Œè€æ©¡æ ‘é™„è¿‘å‘ç°é»‘å½±ç§»åŠ¨ã€‚å¼ ä¸‰ä¸¢å¤±æ–§å¤´ï¼Œåœ°é¢æœ‰å¤§é´å­è„šå°æ­¥ä¼æ€¥ä¿ƒã€‚é»‘å½±èº«é«˜ä¸€ç±³å…«å·¦å³ã€‚æå››æ·±å¤œå¤–å‡ºï¼Œä¸å¼ ä¸‰æœ‰çŸ›ç›¾ï¼Œèº«é«˜ç¬¦åˆã€‚ç‹äº”ä¹Ÿæœ‰å«Œç–‘ä½†æœ‰ä¸åœ¨åœºè¯æ˜ã€‚èµµå…­æ›¾å¨èƒå¼ ä¸‰ä½†èº«é«˜ä¸ç¬¦ã€‚"  # æ¥è¿‘150å­—ç¬¦
    
    context4 = {
        "summary_so_far": max_summary,
        "new_dialogue_chunk": "Gï¼šæˆ‘å‘ç°äº†æ–°çº¿ç´¢ã€‚Hï¼šä»€ä¹ˆçº¿ç´¢ï¼ŸIï¼šæå››çš„å·¥å…·ç®±é‡Œæœ‰è¡€è¿¹ã€‚"
    }
    
    prompt4 = get_prompt("intermediate", context4, model)
    total4 = len(system_prompt) + len(prompt4)
    
    print(f"\n--- åœºæ™¯4ï¼šæé™æƒ…å†µï¼ˆ150å­—ç¬¦æ‘˜è¦ï¼‰ ---")
    print(f"Max summary: '{max_summary}' ({len(max_summary)} chars)")
    print(f"User prompt: '{prompt4}' ({len(prompt4)} chars)")
    print(f"Total length: {total4} chars")
    print(f"âœ… Within 360 limit: {total4 <= 360}")
    print(f"âœ… Summary within 150 limit: {len(max_summary) <= 150}")
    
    # æ±‡æ€»æŠ¥å‘Š
    print(f"\n" + "="*50)
    print(f"ğŸ“‹ Atlas Model Final Optimization Test Summary")
    print(f"="*50)
    print(f"System prompt length: {len(system_prompt)} chars (limit: 80)")
    print(f"Target total limit: 360 chars")
    print(f"Summary content limit: 150 chars")
    print(f"Segmentation: Every 2000 tokens")
    print(f"")
    print(f"Test results:")
    print(f"  ç³»ç»Ÿæç¤ºè¯: {len(system_prompt)} chars - {'âœ… PASS' if len(system_prompt) <= 80 else 'âŒ FAIL'}")
    print(f"  åœºæ™¯1 (åˆå§‹æ‘˜è¦): {total1} chars - {'âœ… PASS' if total1 <= 360 else 'âŒ FAIL'}")
    print(f"  åœºæ™¯2 (æ›´æ–°æ‘˜è¦): {total2} chars - {'âœ… PASS' if total2 <= 360 else 'âŒ FAIL'}")
    print(f"  åœºæ™¯3 (æœ€ç»ˆæ¨ç†): {total3} chars - {'âœ… PASS' if total3 <= 360 else 'âŒ FAIL'}")
    print(f"  åœºæ™¯4 (æé™æƒ…å†µ): {total4} chars - {'âœ… PASS' if total4 <= 360 else 'âŒ FAIL'}")
    
    all_pass = all([
        len(system_prompt) <= 80,
        total1 <= 360, 
        total2 <= 360, 
        total3 <= 360, 
        total4 <= 360,
        len(previous_summary) <= 150,
        len(final_summary) <= 150,
        len(max_summary) <= 150
    ])
    
    print(f"")
    print(f"Overall result: {'âœ… ALL TESTS PASS' if all_pass else 'âŒ SOME TESTS FAIL'}")
    
    if all_pass:
        print(f"ğŸ¯ Atlas model final optimization successful!")
        print(f"âœ… ç³»ç»Ÿæç¤ºè¯ â‰¤ 80å­—ç¬¦")
        print(f"âœ… æ€»ç»“å†…å®¹ä¸¥æ ¼é™åˆ¶åœ¨150å­—ç¬¦ä»¥å†…")
        print(f"âœ… æ€»æç¤ºè¯ä¸¥æ ¼é™åˆ¶åœ¨360å­—ç¬¦ä»¥å†…")
        print(f"âœ… æ¯2000 tokensæ€»ç»“ä¸€æ¬¡ï¼Œé¿å…å¼ºåˆ¶æˆªæ–­")
        print(f"âœ… æ”¯æŒ3ä¸‡å­—ä»¥ä¸Šå†…å®¹å¤šè½®å¤„ç†")
    else:
        print(f"âš ï¸ Some tests failed, need further optimization")

    # è®¡ç®—2000 tokensåˆ†æ®µçš„ä¼˜åŠ¿
    print(f"\nğŸ”„ 2000 Tokens Segmentation Benefits:")
    print(f"â€¢ æ›´é¢‘ç¹çš„æ‘˜è¦æ›´æ–°ï¼Œä¿¡æ¯æŸå¤±æ›´å°‘")
    print(f"â€¢ æ‘˜è¦é•¿åº¦æ›´å®¹æ˜“æ§åˆ¶åœ¨150å­—ç¬¦ä»¥å†…")
    print(f"â€¢ å‡å°‘é›¶å“åº”é—®é¢˜ï¼ˆæ›´å°çš„å¤„ç†å•å…ƒï¼‰")
    print(f"â€¢ æ›´å¥½çš„é•¿ä¸Šä¸‹æ–‡å¤„ç†èƒ½åŠ›")

if __name__ == "__main__":
    test_final_optimization()
