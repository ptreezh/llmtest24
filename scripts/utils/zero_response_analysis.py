#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é›¶å“åº”ç°è±¡åˆ†æå’Œè§£å†³æ–¹æ¡ˆè„šæœ¬
åŸºäºè¯Šæ–­ç»“æœæä¾›å…·ä½“çš„ä¼˜åŒ–å»ºè®®å’Œæµ‹è¯•æ–¹æ¡ˆ
"""

import json
import os
import sys
from datetime import datetime
from typing import Dict, List, Tuple
import ollama

class ZeroResponseAnalyzer:
    def __init__(self):
        # åŠ è½½é…ç½®
        try:
            sys.path.append(os.path.abspath('.'))
            from config import MODEL_TO_TEST
            self.model = MODEL_TO_TEST
        except ImportError:
            print("é”™è¯¯: æ— æ³•å¯¼å…¥é…ç½®æ–‡ä»¶")
            sys.exit(1)
        
        # åŠ è½½è¯Šæ–­ç»“æœ
        self.diagnosis_data = self.load_diagnosis_results()
        
    def load_diagnosis_results(self) -> Dict:
        """åŠ è½½è¯Šæ–­ç»“æœ"""
        try:
            with open('zero_response_diagnosis.json', 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print("è­¦å‘Š: æœªæ‰¾åˆ°è¯Šæ–­ç»“æœæ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ zero_response_diagnosis.py")
            return {}
    
    def analyze_patterns(self):
        """åˆ†æé›¶å“åº”æ¨¡å¼"""
        print("ğŸ” é›¶å“åº”æ¨¡å¼åˆ†æ")
        print("="*50)
        
        if not self.diagnosis_data:
            print("âŒ æ— è¯Šæ–­æ•°æ®å¯åˆ†æ")
            return
        
        stats = self.diagnosis_data.get('statistics', {})
        thresholds = self.diagnosis_data.get('thresholds', {})
        
        print(f"ğŸ“Š å…³é”®å‘ç°:")
        print(f"  â€¢ é›¶å“åº”ç‡: {stats.get('zero_response_rate', 0):.1f}%")
        print(f"  â€¢ é•¿åº¦é˜ˆå€¼: ~{thresholds.get('length_threshold', 'N/A')}å­—ç¬¦")
        print(f"  â€¢ å¤æ‚åº¦é˜ˆå€¼: Level {thresholds.get('complexity_threshold', 'N/A')}")
        
        # åˆ†ææ¨¡å¼
        length_threshold = thresholds.get('length_threshold', 0)
        complexity_threshold = thresholds.get('complexity_threshold', 0)
        
        print(f"\nğŸ¯ é—®é¢˜æ¨¡å¼è¯†åˆ«:")
        
        if length_threshold and length_threshold < 500:
            print(f"  âš ï¸ é•¿åº¦æ•æ„Ÿ: æç¤ºè¯è¶…è¿‡{length_threshold}å­—ç¬¦æ—¶å®¹æ˜“å‡ºç°é›¶å“åº”")
            print(f"    å»ºè®®: å°†å¤æ‚æç¤ºè¯åˆ†è§£ä¸ºå¤šä¸ªè¾ƒçŸ­çš„å­é—®é¢˜")
        
        if complexity_threshold and complexity_threshold <= 4:
            print(f"  âš ï¸ å¤æ‚åº¦æ•æ„Ÿ: Level {complexity_threshold}ä»¥ä¸Šçš„å¤æ‚é—®é¢˜å®¹æ˜“å¤±è´¥")
            print(f"    å»ºè®®: é‡‡ç”¨æ¸è¿›å¼é—®é¢˜åˆ†è§£ç­–ç•¥")
        
        zero_rate = stats.get('zero_response_rate', 0)
        if zero_rate > 15:
            print(f"  âš ï¸ é«˜é›¶å“åº”ç‡: {zero_rate:.1f}%çš„è¯·æ±‚æ— å“åº”")
            print(f"    å»ºè®®: ä¼˜åŒ–æç¤ºè¯ç»“æ„å’Œå‚æ•°è®¾ç½®")
    
    def generate_optimized_prompts(self):
        """ç”Ÿæˆä¼˜åŒ–çš„æç¤ºè¯ç­–ç•¥"""
        print(f"\nğŸ’¡ ä¼˜åŒ–æç¤ºè¯ç­–ç•¥")
        print("="*50)
        
        # åŸºäºé˜ˆå€¼ç”Ÿæˆå»ºè®®
        length_threshold = self.diagnosis_data.get('thresholds', {}).get('length_threshold', 400)
        
        strategies = [
            {
                "name": "åˆ†æ®µå¼æç¤º",
                "description": "å°†é•¿æç¤ºè¯åˆ†è§£ä¸ºå¤šä¸ªçŸ­æ®µ",
                "example": f"åŸå§‹: é•¿æç¤ºè¯({length_threshold + 100}å­—ç¬¦)\nåˆ†è§£: 3ä¸ªçŸ­æç¤ºè¯(å„{length_threshold//3}å­—ç¬¦)"
            },
            {
                "name": "æ¸è¿›å¼å¤æ‚åº¦",
                "description": "ä»ç®€å•é—®é¢˜å¼€å§‹ï¼Œé€æ­¥å¢åŠ å¤æ‚åº¦",
                "example": "Level 1 â†’ Level 2 â†’ Level 3 (è€Œéç›´æ¥Level 4)"
            },
            {
                "name": "ç»“æ„åŒ–æç¤º",
                "description": "ä½¿ç”¨æ¸…æ™°çš„ç»“æ„å’Œæ ‡è®°",
                "example": "ä½¿ç”¨ç¼–å·ã€åˆ†ç‚¹ã€æ˜ç¡®çš„é—®é¢˜é™ˆè¿°"
            },
            {
                "name": "ä¸Šä¸‹æ–‡ç®¡ç†",
                "description": "æ§åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œé¿å…ç´¯ç§¯è¿‡å¤šä¿¡æ¯",
                "example": "å®šæœŸæ¸…ç†å¯¹è¯å†å²ï¼Œä¿æŒç„¦ç‚¹"
            }
        ]
        
        for i, strategy in enumerate(strategies, 1):
            print(f"{i}. {strategy['name']}")
            print(f"   æè¿°: {strategy['description']}")
            print(f"   ç¤ºä¾‹: {strategy['example']}")
            print()
    
    def test_optimized_strategies(self):
        """æµ‹è¯•ä¼˜åŒ–ç­–ç•¥çš„æ•ˆæœ"""
        print(f"ğŸ§ª ä¼˜åŒ–ç­–ç•¥æ•ˆæœæµ‹è¯•")
        print("="*50)
        
        # è·å–å·²çŸ¥çš„é—®é¢˜æç¤ºè¯
        length_threshold = self.diagnosis_data.get('thresholds', {}).get('length_threshold', 400)
        
        # æµ‹è¯•åˆ†æ®µç­–ç•¥
        print("æµ‹è¯•1: åˆ†æ®µç­–ç•¥")
        long_prompt = "è¯·åˆ†æä»¥ä¸‹å¤æ‚å•†ä¸šåœºæ™¯ï¼š" + "è¿™æ˜¯ä¸€ä¸ªåŒ…å«å¤šæ–¹åˆ©ç›Šå†²çªçš„å¤æ‚é—®é¢˜ã€‚" * 20
        
        if len(long_prompt) > length_threshold:
            # åˆ†è§£ä¸ºå¤šä¸ªçŸ­æç¤º
            segments = [
                "è¯·ç®€è¦åˆ†æå•†ä¸šåœºæ™¯ä¸­çš„ä¸»è¦åˆ©ç›Šç›¸å…³è€…ã€‚",
                "è¯·åˆ†æè¿™äº›åˆ©ç›Šç›¸å…³è€…ä¹‹é—´çš„ä¸»è¦å†²çªç‚¹ã€‚",
                "è¯·æå‡ºåˆæ­¥çš„å¹³è¡¡æ–¹æ¡ˆå»ºè®®ã€‚"
            ]
            
            print(f"  åŸå§‹æç¤ºè¯é•¿åº¦: {len(long_prompt)}å­—ç¬¦")
            print(f"  åˆ†è§£ä¸º{len(segments)}ä¸ªæ®µè½:")
            
            success_count = 0
            for i, segment in enumerate(segments, 1):
                print(f"    æ®µè½{i} ({len(segment)}å­—ç¬¦): ", end="")
                
                try:
                    response = ollama.chat(
                        model=self.model,
                        messages=[{'role': 'user', 'content': segment}],
                        options={'timeout': 20}
                    )
                    content = response.get('message', {}).get('content', '')
                    
                    if content:
                        print(f"âœ… æˆåŠŸ ({len(content)}å­—ç¬¦)")
                        success_count += 1
                    else:
                        print("âŒ é›¶å“åº”")
                        
                except Exception as e:
                    print(f"âŒ é”™è¯¯: {str(e)[:50]}...")
            
            success_rate = (success_count / len(segments)) * 100
            print(f"  åˆ†æ®µç­–ç•¥æˆåŠŸç‡: {success_rate:.1f}%")
        
        # æµ‹è¯•æ¸è¿›å¼å¤æ‚åº¦
        print(f"\næµ‹è¯•2: æ¸è¿›å¼å¤æ‚åº¦")
        progressive_prompts = [
            "è¯·åˆ†æï¼šå…¬å¸åº”è¯¥æé«˜ä»·æ ¼è¿˜æ˜¯é™ä½æˆæœ¬ï¼Ÿ",
            "åŸºäºä¸Šè¿°åˆ†æï¼Œå¦‚æœåŒæ—¶é¢ä¸´å®¢æˆ·ä»·æ ¼å‹åŠ›ï¼Œåº”è¯¥å¦‚ä½•è°ƒæ•´ç­–ç•¥ï¼Ÿ",
            "è¿›ä¸€æ­¥è€ƒè™‘å‘˜å·¥è–ªèµ„éœ€æ±‚ï¼Œè¯·å®Œå–„æ•´ä½“å¹³è¡¡æ–¹æ¡ˆã€‚"
        ]
        
        context = []
        success_count = 0
        
        for i, prompt in enumerate(progressive_prompts, 1):
            print(f"  é˜¶æ®µ{i}: ", end="")
            
            # æ„å»ºä¸Šä¸‹æ–‡
            messages = []
            for j, (prev_prompt, prev_response) in enumerate(context):
                messages.extend([
                    {'role': 'user', 'content': prev_prompt},
                    {'role': 'assistant', 'content': prev_response}
                ])
            messages.append({'role': 'user', 'content': prompt})
            
            try:
                response = ollama.chat(
                    model=self.model,
                    messages=messages,
                    options={'timeout': 25}
                )
                content = response.get('message', {}).get('content', '')
                
                if content:
                    print(f"âœ… æˆåŠŸ ({len(content)}å­—ç¬¦)")
                    context.append((prompt, content))
                    success_count += 1
                else:
                    print("âŒ é›¶å“åº”")
                    break
                    
            except Exception as e:
                print(f"âŒ é”™è¯¯: {str(e)[:50]}...")
                break
        
        progressive_success_rate = (success_count / len(progressive_prompts)) * 100
        print(f"  æ¸è¿›å¼ç­–ç•¥æˆåŠŸç‡: {progressive_success_rate:.1f}%")
    
    def generate_recommendations(self):
        """ç”Ÿæˆå…·ä½“çš„ä¼˜åŒ–å»ºè®®"""
        print(f"\nğŸ“‹ å…·ä½“ä¼˜åŒ–å»ºè®®")
        print("="*50)
        
        stats = self.diagnosis_data.get('statistics', {})
        thresholds = self.diagnosis_data.get('thresholds', {})
        
        recommendations = []
        
        # åŸºäºé›¶å“åº”ç‡çš„å»ºè®®
        zero_rate = stats.get('zero_response_rate', 0)
        if zero_rate > 20:
            recommendations.append({
                "priority": "é«˜",
                "category": "æç¤ºè¯ä¼˜åŒ–",
                "action": "ç«‹å³å®æ–½æç¤ºè¯é•¿åº¦æ§åˆ¶",
                "details": f"å°†æç¤ºè¯é™åˆ¶åœ¨{thresholds.get('length_threshold', 400)}å­—ç¬¦ä»¥å†…"
            })
        
        # åŸºäºå¤æ‚åº¦é˜ˆå€¼çš„å»ºè®®
        complexity_threshold = thresholds.get('complexity_threshold', 0)
        if complexity_threshold <= 4:
            recommendations.append({
                "priority": "é«˜",
                "category": "å¤æ‚åº¦ç®¡ç†",
                "action": "é‡‡ç”¨åˆ†æ­¥éª¤é—®é¢˜è§£å†³",
                "details": "å°†Level 4+çš„å¤æ‚é—®é¢˜åˆ†è§£ä¸ºå¤šä¸ªLevel 2-3çš„å­é—®é¢˜"
            })
        
        # é€šç”¨ä¼˜åŒ–å»ºè®®
        recommendations.extend([
            {
                "priority": "ä¸­",
                "category": "å‚æ•°è°ƒä¼˜",
                "action": "ä¼˜åŒ–æ¨¡å‹å‚æ•°",
                "details": "è°ƒæ•´temperatureã€top_pç­‰å‚æ•°ä»¥æé«˜å“åº”ç¨³å®šæ€§"
            },
            {
                "priority": "ä¸­",
                "category": "é‡è¯•æœºåˆ¶",
                "action": "å®æ–½æ™ºèƒ½é‡è¯•",
                "details": "å¯¹é›¶å“åº”æƒ…å†µè‡ªåŠ¨é‡è¯•ï¼Œä½¿ç”¨ä¸åŒçš„æç¤ºè¯å˜ä½“"
            },
            {
                "priority": "ä½",
                "category": "ç›‘æ§ä¼˜åŒ–",
                "action": "å»ºç«‹å“åº”è´¨é‡ç›‘æ§",
                "details": "æŒç»­ç›‘æ§é›¶å“åº”ç‡å’Œå“åº”è´¨é‡æŒ‡æ ‡"
            }
        ])
        
        # è¾“å‡ºå»ºè®®
        for i, rec in enumerate(recommendations, 1):
            priority_emoji = {"é«˜": "ğŸ”´", "ä¸­": "ğŸŸ¡", "ä½": "ğŸŸ¢"}
            print(f"{i}. {priority_emoji[rec['priority']]} {rec['category']}: {rec['action']}")
            print(f"   è¯¦æƒ…: {rec['details']}")
            print()
    
    def run_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸ”¬ é›¶å“åº”ç°è±¡æ·±åº¦åˆ†æ")
        print("="*60)
        print(f"æ¨¡å‹: {self.model}")
        print(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print()
        
        self.analyze_patterns()
        self.generate_optimized_prompts()
        self.test_optimized_strategies()
        self.generate_recommendations()
        
        print("\n" + "="*60)
        print("âœ… åˆ†æå®Œæˆï¼è¯·æ ¹æ®å»ºè®®ä¼˜åŒ–æ‚¨çš„æµ‹è¯•ç­–ç•¥ã€‚")

def main():
    analyzer = ZeroResponseAnalyzer()
    analyzer.run_analysis()

if __name__ == "__main__":
    main()
