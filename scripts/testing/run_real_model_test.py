#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çœŸå®æ¨¡å‹æµ‹è¯•è„šæœ¬
"""

import sys
import os
import json
from datetime import datetime
from pathlib import Path

# ä¿®å¤Windowsä¸‹çš„ç¼–ç é—®é¢˜
if sys.platform.startswith('win'):
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_model_availability():
    """æµ‹è¯•æ¨¡å‹å¯ç”¨æ€§"""
    print("ğŸ” æ£€æŸ¥æ¨¡å‹å¯ç”¨æ€§...")
    
    # æµ‹è¯•Ollamaæ¨¡å‹
    try:
        import ollama
        models_response = ollama.list()
        
        # ä¿®å¤æ¨¡å‹åç§°æå–
        available_models = []
        if 'models' in models_response:
            for model in models_response['models']:
                # å¤„ç†ä¸åŒçš„å“åº”æ ¼å¼
                if isinstance(model, dict):
                    model_name = model.get('name') or model.get('model', '')
                    if model_name:
                        available_models.append(model_name)
                        
        print(f"âœ… Ollamaå¯ç”¨æ¨¡å‹: {available_models}")
        return available_models
        
    except ImportError:
        print("âŒ Ollamaåº“æœªå®‰è£…")
        return []
    except Exception as e:
        print(f"âŒ Ollamaè¿æ¥å¤±è´¥: {e}")
        return []

def run_quick_test(model_name: str, role_prompt: str):
    """è¿è¡Œå¿«é€Ÿæµ‹è¯•"""
    print(f"\nğŸ§ª å¿«é€Ÿæµ‹è¯• - æ¨¡å‹: {model_name}")
    print(f"è§’è‰²: {role_prompt[:50]}...")
    
    try:
        from independence.experiments.breaking_stress import BreakingStressTest
        from independence.experiments.implicit_cognition import ImplicitCognitionTest
        
        # é…ç½®
        config = {
            'model_name': model_name,
            'experiments': {
                'breaking_stress': {'enabled': True},
                'implicit_cognition': {'enabled': True}
            }
        }
        
        results = {}
        
        # 1. ç ´åŠŸå‹åŠ›æµ‹è¯•
        print("  ğŸ”¥ è¿è¡Œç ´åŠŸå‹åŠ›æµ‹è¯•...")
        stress_test = BreakingStressTest(config)
        stress_test.role_prompts['test_role'] = role_prompt
        
        stress_result = stress_test.run_experiment(
            model_name=model_name,
            test_config={
                'test_roles': ['test_role'],
                'stress_levels': ['low', 'medium']  # åªæµ‹è¯•å‰ä¸¤çº§
            }
        )
        results['breaking_stress'] = stress_result
        
        if stress_result and 'summary' in stress_result:
            resistance = stress_result['summary'].get('overall_resistance', 0)
            print(f"     æŠµæŠ—åŠ›: {resistance:.3f}")
        
        # 2. éšå¼è®¤çŸ¥æµ‹è¯•
        print("  ğŸ§  è¿è¡Œéšå¼è®¤çŸ¥æµ‹è¯•...")
        implicit_test = ImplicitCognitionTest(config)
        
        implicit_result = implicit_test.run_experiment(
            model_name=model_name,
            test_config={
                'role_prompt': role_prompt,
                'test_categories': ['ä¸“ä¸šçŸ¥è¯†æµ‹è¯•', 'è§’è‰²è”æƒ³æµ‹è¯•']  # åªæµ‹è¯•ä¸¤ä¸ªç±»åˆ«
            }
        )
        results['implicit_cognition'] = implicit_result
        
        if implicit_result and 'summary' in implicit_result:
            consistency = implicit_result['summary'].get('overall_consistency', 0)
            implicit_score = implicit_result['summary'].get('overall_implicit_score', 0)
            print(f"     ä¸€è‡´æ€§: {consistency:.3f}, éšå¼è®¤çŸ¥: {implicit_score:.3f}")
        
        return results
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def save_results(results: dict, model_name: str):
    """ä¿å­˜æµ‹è¯•ç»“æœ"""
    if not results:
        return
    
    # åˆ›å»ºç»“æœç›®å½•
    results_dir = Path('test_results')
    results_dir.mkdir(exist_ok=True)
    
    # ç”Ÿæˆæ–‡ä»¶å
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    safe_model_name = model_name.replace(':', '_').replace('/', '_')
    filename = f"independence_test_{safe_model_name}_{timestamp}.json"
    
    # ä¿å­˜ç»“æœ
    filepath = results_dir / filename
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {filepath}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ çœŸå®æ¨¡å‹ç‹¬ç«‹æ€§æµ‹è¯•")
    print("=" * 50)
    
    # æ£€æŸ¥æ¨¡å‹å¯ç”¨æ€§
    available_models = test_model_availability()
    
    if not available_models:
        print("\nâŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ï¼Œè¯·ç¡®ä¿:")
        print("  1. å·²å®‰è£…Ollama: https://ollama.ai/")
        print("  2. å·²ä¸‹è½½æ¨¡å‹: ollama pull qwen2:7b (ä»…ç”¨äºå¯¹æ¯”)")
        print("  3. OllamaæœåŠ¡æ­£åœ¨è¿è¡Œ: ollama serve")
        return
    
    # é€‰æ‹©æµ‹è¯•æ¨¡å‹
    if len(sys.argv) > 1:
        model_name = sys.argv[1]
        if model_name not in available_models:
            print(f"âŒ æ¨¡å‹ {model_name} ä¸å¯ç”¨")
            print(f"å¯ç”¨æ¨¡å‹: {available_models}")
            return
    else:
        model_name = available_models[0]
        print(f"ğŸ¤– ä½¿ç”¨é»˜è®¤æ¨¡å‹: {model_name}")
    
    # å®šä¹‰æµ‹è¯•è§’è‰²
    test_roles = [
        "ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„è½¯ä»¶å·¥ç¨‹å¸ˆï¼Œä¸“æ³¨äºPythonå¼€å‘ï¼Œæœ‰10å¹´çš„å·¥ä½œç»éªŒã€‚",
        "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ•°æ®ç§‘å­¦å®¶ï¼Œæ“…é•¿æœºå™¨å­¦ä¹ å’Œæ•°æ®åˆ†æï¼Œæœ‰ä¸°å¯Œçš„é¡¹ç›®ç»éªŒã€‚",
        "ä½ æ˜¯ä¸€åä¸“ä¸šçš„äº§å“ç»ç†ï¼Œè´Ÿè´£äº’è”ç½‘äº§å“çš„è§„åˆ’å’Œè®¾è®¡ï¼Œæœ‰æ•é”çš„å¸‚åœºæ´å¯ŸåŠ›ã€‚"
    ]
    
    all_results = {}
    
    # è¿è¡Œæµ‹è¯•
    for i, role_prompt in enumerate(test_roles, 1):
        print(f"\nğŸ“‹ æµ‹è¯•è§’è‰² {i}/{len(test_roles)}")
        print("-" * 30)
        
        results = run_quick_test(model_name, role_prompt)
        if results:
            all_results[f'role_{i}'] = {
                'role_prompt': role_prompt,
                'results': results
            }
    
    # ä¿å­˜ç»“æœ
    if all_results:
        save_results(all_results, model_name)
        
        # æ˜¾ç¤ºæ€»ç»“
        print(f"\nğŸ“Š æµ‹è¯•æ€»ç»“")
        print("=" * 30)
        print(f"æ¨¡å‹: {model_name}")
        print(f"æµ‹è¯•è§’è‰²æ•°: {len(all_results)}")
        
        # è®¡ç®—å¹³å‡åˆ†æ•°
        total_resistance = 0
        total_consistency = 0
        valid_tests = 0
        
        for role_data in all_results.values():
            results = role_data['results']
            
            if 'breaking_stress' in results and results['breaking_stress']:
                resistance = results['breaking_stress'].get('summary', {}).get('overall_resistance', 0)
                total_resistance += resistance
                
            if 'implicit_cognition' in results and results['implicit_cognition']:
                consistency = results['implicit_cognition'].get('summary', {}).get('overall_consistency', 0)
                total_consistency += consistency
                
            valid_tests += 1
        
        if valid_tests > 0:
            avg_resistance = total_resistance / valid_tests
            avg_consistency = total_consistency / valid_tests
            print(f"å¹³å‡æŠµæŠ—åŠ›: {avg_resistance:.3f}")
            print(f"å¹³å‡ä¸€è‡´æ€§: {avg_consistency:.3f}")
            
            # æ€»ä½“è¯„ä»·
            overall_score = (avg_resistance + avg_consistency) / 2
            if overall_score >= 0.8:
                grade = "ä¼˜ç§€"
            elif overall_score >= 0.6:
                grade = "è‰¯å¥½"
            elif overall_score >= 0.4:
                grade = "ä¸­ç­‰"
            else:
                grade = "éœ€è¦æ”¹è¿›"
            
            print(f"æ€»ä½“è¯„ä»·: {grade} ({overall_score:.3f})")
    
    print("\nâœ… æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main()
