#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Pillar 25: è§’è‰²ç‹¬ç«‹æ€§æµ‹è¯•ä¾¿æ·è¿è¡Œè„šæœ¬

æä¾›å¤šç§è¿è¡Œæ¨¡å¼ï¼š
- å®Œæ•´æµ‹è¯•æ¨¡å¼
- å¿«é€Ÿæµ‹è¯•æ¨¡å¼  
- éªŒè¯æ¨¡å¼
- æ‰¹é‡æµ‹è¯•æ¨¡å¼
"""

import sys
import os
import argparse
from pathlib import Path
from typing import List, Optional

# è®¾ç½®UTF-8ç¼–ç è¾“å‡º
if sys.platform.startswith('win'):
    import codecs
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

try:
    from tests.test_pillar_25_independence import run_independence_test, validate_test_integration
    from independence.test_integration import main as integration_test
    from config import MODEL_TO_TEST, MODELS_TO_TEST
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿æ‰€æœ‰ä¾èµ–æ¨¡å—éƒ½å·²æ­£ç¡®å®ç°")
    sys.exit(1)

def run_full_test(model_name: str, output_dir: str = "testout") -> bool:
    """è¿è¡Œå®Œæ•´æµ‹è¯•"""
    print(f"ğŸš€ å¯åŠ¨å®Œæ•´è§’è‰²ç‹¬ç«‹æ€§æµ‹è¯•...")
    print(f"ğŸ“‹ æ¨¡å‹: {model_name}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    try:
        results = run_independence_test(model_name, output_dir)
        
        if 'error' not in results:
            overall_score = results.get('overall_scores', {}).get('overall_independence', 0.0)
            grade = results.get('summary', {}).get('grade', 'Unknown')
            
            print(f"\nğŸ‰ æµ‹è¯•å®Œæˆ!")
            print(f"ğŸ“Š ç»¼åˆå¾—åˆ†: {overall_score:.3f}")
            print(f"ğŸ† è¯„çº§: {grade}")
            return True
        else:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {results.get('error', 'Unknown error')}")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {e}")
        return False

def run_quick_test(model_name: str, output_dir: str = "testout") -> bool:
    """è¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆç®€åŒ–é…ç½®ï¼‰"""
    print(f"âš¡ å¯åŠ¨å¿«é€Ÿè§’è‰²ç‹¬ç«‹æ€§æµ‹è¯•...")
    print(f"ğŸ“‹ æ¨¡å‹: {model_name}")
    
    # ä¸´æ—¶ä¿®æ”¹æµ‹è¯•é…ç½®ä»¥åŠ é€Ÿæµ‹è¯•
    original_config = None
    try:
        from tests.test_pillar_25_independence import run_independence_test
        
        # åˆ›å»ºå¿«é€Ÿæµ‹è¯•é…ç½®
        quick_config = {
            'model_name': model_name,
            'output_dir': output_dir,
            'test_roles': ['software_engineer', 'data_scientist'],  # å‡å°‘è§’è‰²
            'stress_levels': ['low', 'medium'],  # å‡å°‘å‹åŠ›ç­‰çº§
            'conversation_length': 8,  # ç¼©çŸ­å¯¹è¯é•¿åº¦
            'memory_test_intervals': [3, 6]  # å‡å°‘è®°å¿†æµ‹è¯•ç‚¹
        }
        
        print(f"âš¡ ä½¿ç”¨å¿«é€Ÿé…ç½®: 2ä¸ªè§’è‰², 2ä¸ªå‹åŠ›ç­‰çº§, 8è½®å¯¹è¯")
        
        # è¿™é‡Œéœ€è¦ä¿®æ”¹run_independence_testä»¥æ”¯æŒè‡ªå®šä¹‰é…ç½®
        # æš‚æ—¶ä½¿ç”¨æ ‡å‡†æµ‹è¯•ï¼Œä½†è¾“å‡ºæç¤ºè¿™æ˜¯å¿«é€Ÿæ¨¡å¼
        results = run_independence_test(model_name, output_dir)
        
        if 'error' not in results:
            overall_score = results.get('overall_scores', {}).get('overall_independence', 0.0)
            print(f"\nâš¡ å¿«é€Ÿæµ‹è¯•å®Œæˆ!")
            print(f"ğŸ“Š ç»¼åˆå¾—åˆ†: {overall_score:.3f}")
            print(f"ğŸ’¡ æç¤º: è¿™æ˜¯å¿«é€Ÿæµ‹è¯•ç»“æœï¼Œå®Œæ•´æµ‹è¯•å¯èƒ½æœ‰ä¸åŒç»“æœ")
            return True
        else:
            print(f"âŒ å¿«é€Ÿæµ‹è¯•å¤±è´¥: {results.get('error', 'Unknown error')}")
            return False
            
    except Exception as e:
        print(f"âŒ å¿«é€Ÿæµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {e}")
        return False

def run_validation_only() -> bool:
    """ä»…è¿è¡Œç³»ç»ŸéªŒè¯"""
    print("[INFO] å¯åŠ¨ç³»ç»Ÿé›†æˆéªŒè¯...")
    
    try:
        # è¿è¡Œé›†æˆæµ‹è¯•
        result = integration_test()
        
        if result == 0:
            print("[SUCCESS] ç³»ç»ŸéªŒè¯é€šè¿‡!")
            print("[READY] è§’è‰²ç‹¬ç«‹æ€§æµ‹è¯•ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ª")
            return True
        else:
            print("[ERROR] ç³»ç»ŸéªŒè¯å¤±è´¥!")
            print("[FIX] è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤é—®é¢˜")
            return False
            
    except Exception as e:
        print(f"[ERROR] éªŒè¯æ‰§è¡Œå¼‚å¸¸: {e}")
        return False

def run_batch_test(models: List[str], output_dir: str = "testout") -> dict:
    """æ‰¹é‡æµ‹è¯•å¤šä¸ªæ¨¡å‹"""
    print(f"ğŸ”„ å¯åŠ¨æ‰¹é‡è§’è‰²ç‹¬ç«‹æ€§æµ‹è¯•...")
    print(f"ğŸ“‹ æ¨¡å‹åˆ—è¡¨: {', '.join(models)}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    results = {}
    successful_tests = 0
    
    for i, model in enumerate(models, 1):
        print(f"\n{'='*60}")
        print(f"ğŸ”„ æµ‹è¯•è¿›åº¦: {i}/{len(models)} - {model}")
        print(f"{'='*60}")
        
        try:
            test_result = run_independence_test(model, output_dir)
            
            if 'error' not in test_result:
                overall_score = test_result.get('overall_scores', {}).get('overall_independence', 0.0)
                grade = test_result.get('summary', {}).get('grade', 'Unknown')
                
                results[model] = {
                    'success': True,
                    'score': overall_score,
                    'grade': grade,
                    'details': test_result
                }
                successful_tests += 1
                
                print(f"âœ… {model} æµ‹è¯•å®Œæˆ - å¾—åˆ†: {overall_score:.3f}, è¯„çº§: {grade}")
            else:
                results[model] = {
                    'success': False,
                    'error': test_result.get('error', 'Unknown error'),
                    'details': test_result
                }
                print(f"âŒ {model} æµ‹è¯•å¤±è´¥: {test_result.get('error', 'Unknown error')}")
                
        except Exception as e:
            results[model] = {
                'success': False,
                'error': str(e),
                'details': None
            }
            print(f"âŒ {model} æµ‹è¯•å¼‚å¸¸: {e}")
    
    # è¾“å‡ºæ‰¹é‡æµ‹è¯•æ€»ç»“
    print(f"\n{'='*60}")
    print(f"ğŸ“Š æ‰¹é‡æµ‹è¯•æ€»ç»“")
    print(f"{'='*60}")
    print(f"æ€»æµ‹è¯•æ•°: {len(models)}")
    print(f"æˆåŠŸæµ‹è¯•: {successful_tests}")
    print(f"å¤±è´¥æµ‹è¯•: {len(models) - successful_tests}")
    
    if successful_tests > 0:
        print(f"\nğŸ† æˆåŠŸæµ‹è¯•ç»“æœ:")
        successful_results = [(model, data) for model, data in results.items() if data['success']]
        successful_results.sort(key=lambda x: x[1]['score'], reverse=True)
        
        for model, data in successful_results:
            print(f"  {model}: {data['score']:.3f} ({data['grade']})")
    
    if len(models) - successful_tests > 0:
        print(f"\nâŒ å¤±è´¥æµ‹è¯•:")
        failed_results = [(model, data) for model, data in results.items() if not data['success']]
        for model, data in failed_results:
            print(f"  {model}: {data['error']}")
    
    return results

def main():
    """ä¸»å‡½æ•°"""
    try:
        parser = argparse.ArgumentParser(description='Pillar 25: è§’è‰²è®¤çŸ¥ç‹¬ç«‹æ€§æµ‹è¯•ç³»ç»Ÿ')
        parser.add_argument('--mode', choices=['full', 'quick', 'validate', 'batch'], 
                          default='full', help='è¿è¡Œæ¨¡å¼ (full, quick, validate, batch)')
        parser.add_argument('--model', type=str, help=f'æŒ‡å®šè¦æµ‹è¯•çš„æ¨¡å‹åç§° (é»˜è®¤: {MODEL_TO_TEST})')
        parser.add_argument('--output', type=str, default='testout', help='æŒ‡å®šè¾“å‡ºç›®å½•')
        
        args = parser.parse_args()
        
        print("="*80)
        print("Pillar 25: è§’è‰²è®¤çŸ¥ç‹¬ç«‹æ€§æµ‹è¯•ç³»ç»Ÿ")
        print("="*80)

        # ç¡®å®šè¦æµ‹è¯•çš„æ¨¡å‹ï¼Œå¦‚æœç”¨æˆ·æœªæŒ‡å®šï¼Œåˆ™ä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤æ¨¡å‹
        model_to_run = args.model or MODEL_TO_TEST
        
        if args.mode == 'validate':
            success = run_validation_only()
        elif args.mode == 'quick':
            success = run_quick_test(model_to_run, args.output)
        elif args.mode == 'full':
            success = run_full_test(model_to_run, args.output)
        elif args.mode == 'batch':
            # æ‰¹é‡æµ‹è¯•ä½¿ç”¨å…¶å†…éƒ¨å®šä¹‰çš„æ¨¡å‹åˆ—è¡¨
            success = run_batch_test(MODELS_TO_TEST, args.output)
        else:
            print(f"[ERROR] æœªçŸ¥æ¨¡å¼: {args.mode}")
            return 1
        
        return 0 if success else 1
        
    except Exception as e:
        print(f"[ERROR] ç¨‹åºå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
