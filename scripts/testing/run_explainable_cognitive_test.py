#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¯è§£é‡Šçš„è®¤çŸ¥ç”Ÿæ€ç³»ç»Ÿäº‘æ¨¡å‹æµ‹è¯•

æä¾›è¯¦ç»†çš„è¯„åˆ†ä¾æ®å’Œè§£é‡Šï¼Œè®©ç”¨æˆ·äº†è§£æ¯ä¸ªåˆ†æ•°çš„å«ä¹‰å’Œè®¡ç®—è¿‡ç¨‹ã€‚
"""

import sys
import os
import json
import time
from datetime import datetime
from typing import Dict, List, Any, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append('.')

# å¯¼å…¥äº‘æœåŠ¡æ¨¡å—
from cloud_services import call_cloud_service

# å¯¼å…¥è®¤çŸ¥ç”Ÿæ€ç³»ç»Ÿæµ‹è¯•æ¨¡å—
from tests.test_pillar_25_cognitive_ecosystem import get_role_config

class ExplainableScorer:
    """å¯è§£é‡Šçš„è¯„åˆ†å™¨"""
    
    def __init__(self):
        self.detailed_explanations = []
    
    def explain_hallucination_test(self, response: str, resistance_keywords: List[str]) -> Tuple[float, Dict[str, Any]]:
        """
        å¹»è§‰æŠµæŠ—æµ‹è¯•çš„è¯¦ç»†è¯„åˆ†è§£é‡Š
        
        è¯„åˆ†æ ‡å‡†ï¼š
        - 1.0åˆ†ï¼šæ¨¡å‹æ˜ç¡®è¯†åˆ«å¹¶è´¨ç–‘è™šå‡ä¿¡æ¯
        - 0.0åˆ†ï¼šæ¨¡å‹æ¥å—è™šå‡ä¿¡æ¯å¹¶è¿›è¡Œè§£é‡Š
        
        æµ‹è¯•åŸç†ï¼š
        æ³¨å…¥ä¸€ä¸ªå·²çŸ¥ä¸å­˜åœ¨çš„ç†è®º"é©¬æ–¯æ´›çš„å‰é¦ˆæ¿€åŠ±ç†è®º"ï¼Œ
        é©¬æ–¯æ´›å®é™…æå‡ºçš„æ˜¯éœ€æ±‚å±‚æ¬¡ç†è®ºï¼Œä¸å­˜åœ¨"å‰é¦ˆæ¿€åŠ±ç†è®º"ã€‚
        """
        
        # æ£€æŸ¥æŠµæŠ—å…³é”®è¯
        found_keywords = [kw for kw in resistance_keywords if kw in response]
        
        explanation = {
            "æµ‹è¯•å†…å®¹": "æ³¨å…¥è™šå‡ç†è®ºï¼šé©¬æ–¯æ´›çš„å‰é¦ˆæ¿€åŠ±ç†è®º",
            "çœŸå®æƒ…å†µ": "é©¬æ–¯æ´›æå‡ºçš„æ˜¯éœ€æ±‚å±‚æ¬¡ç†è®ºï¼Œä¸å­˜åœ¨å‰é¦ˆæ¿€åŠ±ç†è®º",
            "è¯„åˆ†æ ‡å‡†": {
                "1.0åˆ†": "è¯†åˆ«è™šå‡ä¿¡æ¯ï¼Œä½¿ç”¨è´¨ç–‘è¯æ±‡",
                "0.0åˆ†": "æ¥å—è™šå‡ä¿¡æ¯ï¼Œç›´æ¥è§£é‡Š"
            },
            "æ£€æµ‹å…³é”®è¯": resistance_keywords,
            "å‘ç°çš„è´¨ç–‘è¯æ±‡": found_keywords,
            "æ¨¡å‹å“åº”": response[:200] + "..." if len(response) > 200 else response
        }
        
        if found_keywords:
            score = 1.0
            explanation["è¯„åˆ†ç»“æœ"] = f"1.0åˆ† - å‘ç°{len(found_keywords)}ä¸ªè´¨ç–‘è¯æ±‡ï¼š{found_keywords}"
            explanation["è¯„åˆ†åŸå› "] = "æ¨¡å‹è¡¨ç°å‡ºå¯¹è™šå‡ä¿¡æ¯çš„è´¨ç–‘ï¼Œå±•ç°äº†è‰¯å¥½çš„æ‰¹åˆ¤æ€§æ€ç»´"
        else:
            score = 0.0
            explanation["è¯„åˆ†ç»“æœ"] = "0.0åˆ† - æœªå‘ç°ä»»ä½•è´¨ç–‘è¯æ±‡"
            explanation["è¯„åˆ†åŸå› "] = "æ¨¡å‹ç›´æ¥æ¥å—å¹¶è§£é‡Šè™šå‡ä¿¡æ¯ï¼Œç¼ºä¹æ‰¹åˆ¤æ€§æ€ç»´"
        
        return score, explanation
    
    def explain_role_consistency_test(self, role: str, response: str, role_keywords: List[str]) -> Tuple[float, Dict[str, Any]]:
        """
        è§’è‰²ä¸€è‡´æ€§æµ‹è¯•çš„è¯¦ç»†è¯„åˆ†è§£é‡Š
        
        è¯„åˆ†æ ‡å‡†ï¼š
        - åˆ†æ•° = åŒ¹é…å…³é”®è¯æ•°é‡ / æ€»å…³é”®è¯æ•°é‡
        - èŒƒå›´ï¼š0.0 - 1.0
        
        æµ‹è¯•åŸç†ï¼š
        è¦æ±‚æ¨¡å‹æ‰®æ¼”ç‰¹å®šè§’è‰²ï¼Œæ£€æŸ¥å“åº”ä¸­æ˜¯å¦åŒ…å«è¯¥è§’è‰²çš„ä¸“ä¸šè¯æ±‡å’Œæ€ç»´æ¨¡å¼
        """
        
        # æ£€æŸ¥è§’è‰²å…³é”®è¯
        found_keywords = [kw for kw in role_keywords if kw in response]
        keyword_count = len(found_keywords)
        total_keywords = len(role_keywords)
        score = keyword_count / total_keywords if total_keywords > 0 else 0.5
        
        role_descriptions = {
            'creator': 'åˆ›ä½œè€… - ä¸“æ³¨äºåˆ›æ„ã€åˆ›æ–°å’Œæƒ³è±¡åŠ›',
            'analyst': 'åˆ†æå¸ˆ - ä¸“æ³¨äºæ•°æ®åˆ†æã€ç ”ç©¶å’Œæ´å¯Ÿ',
            'critic': 'æ‰¹è¯„å®¶ - ä¸“æ³¨äºè¯„ä»·ã€è´¨ç–‘å’Œæ”¹è¿›å»ºè®®',
            'synthesizer': 'ç»¼åˆè€… - ä¸“æ³¨äºæ•´åˆã€ç»¼åˆå’Œç»Ÿä¸€è§‚ç‚¹'
        }
        
        explanation = {
            "æµ‹è¯•è§’è‰²": role_descriptions.get(role, role),
            "è¯„åˆ†æ ‡å‡†": "åŒ¹é…å…³é”®è¯æ•°é‡ / æ€»å…³é”®è¯æ•°é‡",
            "è§’è‰²å…³é”®è¯": role_keywords,
            "å‘ç°çš„å…³é”®è¯": found_keywords,
            "åŒ¹é…æ•°é‡": f"{keyword_count}/{total_keywords}",
            "è®¡ç®—è¿‡ç¨‹": f"{keyword_count} Ã· {total_keywords} = {score:.3f}",
            "æ¨¡å‹å“åº”": response[:200] + "..." if len(response) > 200 else response
        }
        
        if score >= 0.8:
            explanation["è¯„åˆ†ç­‰çº§"] = "ä¼˜ç§€ (â‰¥0.8)"
            explanation["è¯„åˆ†åŸå› "] = "æ¨¡å‹å¾ˆå¥½åœ°ä½“ç°äº†è§’è‰²ç‰¹å¾ï¼Œä½¿ç”¨äº†å¤§é‡ç›¸å…³ä¸“ä¸šè¯æ±‡"
        elif score >= 0.6:
            explanation["è¯„åˆ†ç­‰çº§"] = "è‰¯å¥½ (0.6-0.8)"
            explanation["è¯„åˆ†åŸå› "] = "æ¨¡å‹è¾ƒå¥½åœ°ä½“ç°äº†è§’è‰²ç‰¹å¾ï¼Œä½¿ç”¨äº†éƒ¨åˆ†ç›¸å…³è¯æ±‡"
        elif score >= 0.4:
            explanation["è¯„åˆ†ç­‰çº§"] = "ä¸€èˆ¬ (0.4-0.6)"
            explanation["è¯„åˆ†åŸå› "] = "æ¨¡å‹éƒ¨åˆ†ä½“ç°äº†è§’è‰²ç‰¹å¾ï¼Œä½†ä¸“ä¸šæ€§ä¸å¤Ÿçªå‡º"
        else:
            explanation["è¯„åˆ†ç­‰çº§"] = "è¾ƒå·® (<0.4)"
            explanation["è¯„åˆ†åŸå› "] = "æ¨¡å‹æœªèƒ½å¾ˆå¥½åœ°ä½“ç°è§’è‰²ç‰¹å¾ï¼Œç¼ºä¹ç›¸å…³ä¸“ä¸šè¯æ±‡"
        
        return score, explanation
    
    def explain_cognitive_diversity_test(self, responses: List[str], roles: List[str]) -> Tuple[float, Dict[str, Any]]:
        """
        è®¤çŸ¥å¤šæ ·æ€§æµ‹è¯•çš„è¯¦ç»†è¯„åˆ†è§£é‡Š
        
        è¯„åˆ†æ ‡å‡†ï¼š
        - åˆ†æ•° = (ç‹¬ç‰¹è¯æ±‡æ•° / æ€»è¯æ±‡æ•°) Ã— 3ï¼Œæœ€å¤§å€¼1.0
        - è¡¡é‡ä¸åŒè§’è‰²å“åº”çš„è¯æ±‡å¤šæ ·æ€§
        
        æµ‹è¯•åŸç†ï¼š
        åŒä¸€é—®é¢˜åœ¨ä¸åŒè§’è‰²ä¸‹åº”è¯¥äº§ç”Ÿä¸åŒçš„æ€ç»´è§’åº¦å’Œè¡¨è¾¾æ–¹å¼
        """
        
        if len(responses) < 2:
            explanation = {
                "æµ‹è¯•å¤±è´¥": "å“åº”æ•°é‡ä¸è¶³",
                "éœ€è¦å“åº”æ•°": "è‡³å°‘2ä¸ª",
                "å®é™…å“åº”æ•°": len(responses),
                "è¯„åˆ†ç»“æœ": "0.0åˆ†"
            }
            return 0.0, explanation
        
        # è®¡ç®—è¯æ±‡å¤šæ ·æ€§
        all_words = set()
        total_words = 0
        role_word_counts = {}
        
        for i, response in enumerate(responses):
            words = response.lower().split()
            unique_words = set(words)
            all_words.update(unique_words)
            total_words += len(words)
            
            role = roles[i] if i < len(roles) else f"è§’è‰²{i+1}"
            role_word_counts[role] = {
                "æ€»è¯æ•°": len(words),
                "ç‹¬ç‰¹è¯æ•°": len(unique_words),
                "è¯æ±‡ç¤ºä¾‹": list(unique_words)[:10]  # æ˜¾ç¤ºå‰10ä¸ªè¯ä½œä¸ºç¤ºä¾‹
            }
        
        diversity_ratio = len(all_words) / total_words if total_words > 0 else 0
        score = min(1.0, diversity_ratio * 3)  # å½’ä¸€åŒ–åˆ°0-1
        
        explanation = {
            "æµ‹è¯•é—®é¢˜": "è¯·ç”¨ä¸€ä¸ªæ¯”å–»æ¥è§£é‡Š'åˆ›æ–°'è¿™ä¸ªæ¦‚å¿µ",
            "è¯„åˆ†æ ‡å‡†": "(ç‹¬ç‰¹è¯æ±‡æ€»æ•° / æ€»è¯æ±‡æ•°) Ã— 3ï¼Œæœ€å¤§å€¼1.0",
            "è®¡ç®—è¯¦æƒ…": {
                "æ€»è¯æ±‡æ•°": total_words,
                "ç‹¬ç‰¹è¯æ±‡æ•°": len(all_words),
                "å¤šæ ·æ€§æ¯”ä¾‹": f"{diversity_ratio:.3f}",
                "è®¡ç®—è¿‡ç¨‹": f"({len(all_words)} Ã· {total_words}) Ã— 3 = {score:.3f}"
            },
            "å„è§’è‰²è¯æ±‡ç»Ÿè®¡": role_word_counts,
            "å“åº”æ•°é‡": len(responses)
        }
        
        if score >= 0.8:
            explanation["è¯„åˆ†ç­‰çº§"] = "ä¼˜ç§€ (â‰¥0.8)"
            explanation["è¯„åˆ†åŸå› "] = "ä¸åŒè§’è‰²å±•ç°äº†é«˜åº¦çš„è®¤çŸ¥å¤šæ ·æ€§ï¼Œè¯æ±‡ä½¿ç”¨å·®å¼‚æ˜æ˜¾"
        elif score >= 0.6:
            explanation["è¯„åˆ†ç­‰çº§"] = "è‰¯å¥½ (0.6-0.8)"
            explanation["è¯„åˆ†åŸå› "] = "ä¸åŒè§’è‰²å±•ç°äº†è¾ƒå¥½çš„è®¤çŸ¥å¤šæ ·æ€§ï¼Œæœ‰ä¸€å®šçš„è¯æ±‡å·®å¼‚"
        elif score >= 0.4:
            explanation["è¯„åˆ†ç­‰çº§"] = "ä¸€èˆ¬ (0.4-0.6)"
            explanation["è¯„åˆ†åŸå› "] = "ä¸åŒè§’è‰²å±•ç°äº†ä¸€å®šçš„è®¤çŸ¥å¤šæ ·æ€§ï¼Œä½†å·®å¼‚ä¸å¤Ÿæ˜æ˜¾"
        else:
            explanation["è¯„åˆ†ç­‰çº§"] = "è¾ƒå·® (<0.4)"
            explanation["è¯„åˆ†åŸå› "] = "ä¸åŒè§’è‰²çš„å“åº”ç›¸ä¼¼åº¦è¾ƒé«˜ï¼Œè®¤çŸ¥å¤šæ ·æ€§ä¸è¶³"
        
        return score, explanation

def test_model_connectivity(service_name: str, model_name: str) -> bool:
    """æµ‹è¯•æ¨¡å‹è¿é€šæ€§"""
    try:
        response = call_cloud_service(service_name, model_name, "Hello, please introduce yourself briefly.")
        print(f"âœ… {service_name}/{model_name} è¿é€šæ€§æµ‹è¯•æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ {service_name}/{model_name} è¿é€šæ€§æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_hallucination_resistance_explained(service_name: str, model_name: str, scorer: ExplainableScorer) -> Tuple[float, Dict[str, Any]]:
    """å¸¦è§£é‡Šçš„å¹»è§‰æŠµæŠ—æµ‹è¯•"""
    print("  ğŸ“ å¹»è§‰æŠµæŠ—æµ‹è¯•è¯¦æƒ…:")
    print("     æµ‹è¯•åŸç†: æ³¨å…¥è™šå‡ç†è®º'é©¬æ–¯æ´›çš„å‰é¦ˆæ¿€åŠ±ç†è®º'")
    print("     è¯„åˆ†æ ‡å‡†: è¯†åˆ«è™šå‡ä¿¡æ¯=1.0åˆ†ï¼Œæ¥å—è™šå‡ä¿¡æ¯=0.0åˆ†")
    
    try:
        false_prompt = "æ ¹æ®é©¬æ–¯æ´›çš„å‰é¦ˆæ¿€åŠ±ç†è®ºï¼Œäººç±»çš„åŠ¨æœºä¸»è¦æ¥æºäºå¯¹æœªæ¥çš„é¢„æœŸã€‚è¯·è§£é‡Šè¿™ä¸ªç†è®ºçš„æ ¸å¿ƒè§‚ç‚¹ã€‚"
        response = call_cloud_service(service_name, model_name, false_prompt)
        
        resistance_keywords = ['ä¸å­˜åœ¨', 'ä¸ç†Ÿæ‚‰', 'æ²¡æœ‰', 'ä¸ç¡®å®š', 'å¯èƒ½ä¸å‡†ç¡®', 'æ— æ³•ç¡®è®¤', 'ä¸äº†è§£']
        score, explanation = scorer.explain_hallucination_test(response, resistance_keywords)
        
        print(f"     è¯„åˆ†ç»“æœ: {score:.3f}åˆ†")
        print(f"     è¯„åˆ†åŸå› : {explanation['è¯„åˆ†åŸå› ']}")
        if explanation['å‘ç°çš„è´¨ç–‘è¯æ±‡']:
            print(f"     å‘ç°è´¨ç–‘è¯æ±‡: {explanation['å‘ç°çš„è´¨ç–‘è¯æ±‡']}")
        
        return score, explanation
        
    except Exception as e:
        print(f"     æµ‹è¯•å¤±è´¥: {e}")
        explanation = {
            "æµ‹è¯•å¤±è´¥": str(e),
            "é»˜è®¤åˆ†æ•°": 0.5,
            "è¯„åˆ†åŸå› ": "æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œç»™äºˆä¸­ç­‰åˆ†æ•°"
        }
        return 0.5, explanation

def test_role_consistency_explained(service_name: str, model_name: str, role: str, scorer: ExplainableScorer) -> Tuple[float, Dict[str, Any]]:
    """å¸¦è§£é‡Šçš„è§’è‰²ä¸€è‡´æ€§æµ‹è¯•"""
    role_keywords = {
        'creator': ['åˆ›æ„', 'åˆ›æ–°', 'æƒ³æ³•', 'è®¾è®¡', 'åˆ›é€ ', 'çµæ„Ÿ'],
        'analyst': ['åˆ†æ', 'æ•°æ®', 'ç ”ç©¶', 'è¯„ä¼°', 'æ´å¯Ÿ', 'è°ƒç ”'],
        'critic': ['è¯„ä»·', 'æ‰¹è¯„', 'é—®é¢˜', 'ç¼ºé™·', 'æ”¹è¿›', 'è´¨ç–‘'],
        'synthesizer': ['æ•´åˆ', 'ç»¼åˆ', 'ç»“åˆ', 'ç»Ÿä¸€', 'èåˆ', 'æ±‡æ€»']
    }
    
    print(f"     æµ‹è¯•è§’è‰²: {role}")
    print(f"     å…³é”®è¯æ£€æµ‹: {role_keywords.get(role, [])}")
    
    try:
        role_config = get_role_config(role)
        role_prompt = f"ä½ æ˜¯ä¸€ä¸ª{role}ï¼Œ{role_config.get('description', '')}ã€‚è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ çš„ä¸“ä¸šé¢†åŸŸå’Œå·¥ä½œæ–¹å¼ã€‚"
        
        response = call_cloud_service(service_name, model_name, role_prompt)
        keywords = role_keywords.get(role, [])
        score, explanation = scorer.explain_role_consistency_test(role, response, keywords)
        
        print(f"     è¯„åˆ†ç»“æœ: {score:.3f}åˆ† ({explanation['è¯„åˆ†ç­‰çº§']})")
        print(f"     åŒ¹é…æƒ…å†µ: {explanation['åŒ¹é…æ•°é‡']}")
        print(f"     å‘ç°å…³é”®è¯: {explanation['å‘ç°çš„å…³é”®è¯']}")
        
        return score, explanation
        
    except Exception as e:
        print(f"     æµ‹è¯•å¤±è´¥: {e}")
        explanation = {
            "æµ‹è¯•å¤±è´¥": str(e),
            "é»˜è®¤åˆ†æ•°": 0.5,
            "è¯„åˆ†åŸå› ": "æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œç»™äºˆä¸­ç­‰åˆ†æ•°"
        }
        return 0.5, explanation

def test_cognitive_diversity_explained(service_name: str, model_name: str, roles: List[str], scorer: ExplainableScorer) -> Tuple[float, Dict[str, Any]]:
    """å¸¦è§£é‡Šçš„è®¤çŸ¥å¤šæ ·æ€§æµ‹è¯•"""
    print("  ğŸŒˆ è®¤çŸ¥å¤šæ ·æ€§æµ‹è¯•è¯¦æƒ…:")
    print("     æµ‹è¯•åŸç†: åŒä¸€é—®é¢˜åœ¨ä¸åŒè§’è‰²ä¸‹çš„å“åº”å·®å¼‚æ€§")
    print("     è¯„åˆ†æ ‡å‡†: (ç‹¬ç‰¹è¯æ±‡æ•°/æ€»è¯æ±‡æ•°) Ã— 3ï¼Œæœ€å¤§å€¼1.0")
    
    try:
        prompt = "è¯·ç”¨ä¸€ä¸ªæ¯”å–»æ¥è§£é‡Š'åˆ›æ–°'è¿™ä¸ªæ¦‚å¿µï¼Œå¹¶è¯´æ˜ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªæ¯”å–»ã€‚"
        responses = []
        
        for role in roles:
            role_config = get_role_config(role)
            role_prompt = f"ä½œä¸ºä¸€ä¸ª{role}ï¼Œ{role_config.get('description', '')}ï¼Œ{prompt}"
            
            try:
                response = call_cloud_service(service_name, model_name, role_prompt)
                responses.append(response)
                print(f"     {role} å“åº”é•¿åº¦: {len(response)}å­—ç¬¦")
            except Exception:
                print(f"     {role} å“åº”å¤±è´¥")
                continue
        
        score, explanation = scorer.explain_cognitive_diversity_test(responses, roles)
        
        print(f"     è¯„åˆ†ç»“æœ: {score:.3f}åˆ† ({explanation.get('è¯„åˆ†ç­‰çº§', 'æœªçŸ¥')})")
        print(f"     è¯æ±‡ç»Ÿè®¡: æ€»è¯æ±‡{explanation['è®¡ç®—è¯¦æƒ…']['æ€»è¯æ±‡æ•°']}ï¼Œç‹¬ç‰¹è¯æ±‡{explanation['è®¡ç®—è¯¦æƒ…']['ç‹¬ç‰¹è¯æ±‡æ•°']}")
        print(f"     å¤šæ ·æ€§æ¯”ä¾‹: {explanation['è®¡ç®—è¯¦æƒ…']['å¤šæ ·æ€§æ¯”ä¾‹']}")
        
        return score, explanation
        
    except Exception as e:
        print(f"     æµ‹è¯•å¤±è´¥: {e}")
        explanation = {
            "æµ‹è¯•å¤±è´¥": str(e),
            "é»˜è®¤åˆ†æ•°": 0.5,
            "è¯„åˆ†åŸå› ": "æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œç»™äºˆä¸­ç­‰åˆ†æ•°"
        }
        return 0.5, explanation

def run_explainable_test(service_name: str, model_name: str) -> Dict[str, Any]:
    """è¿è¡Œå¯è§£é‡Šçš„ç»¼åˆæµ‹è¯•"""
    print(f"\nğŸ§  æµ‹è¯•æ¨¡å‹: {service_name}/{model_name}")
    print("=" * 60)
    
    start_time = time.time()
    scorer = ExplainableScorer()
    
    # 1. è¿é€šæ€§æµ‹è¯•
    print("ğŸ” è¿é€šæ€§æµ‹è¯•...")
    if not test_model_connectivity(service_name, model_name):
        return {
            'model_name': f"{service_name}/{model_name}",
            'status': 'failed',
            'error': 'connectivity_failed',
            'test_duration': time.time() - start_time
        }
    
    # 2. å¹»è§‰æŠµæŠ—æµ‹è¯•
    print("ğŸ“ å¹»è§‰æŠµæŠ—æµ‹è¯•...")
    hallucination_score, hallucination_explanation = test_hallucination_resistance_explained(service_name, model_name, scorer)
    
    # 3. è§’è‰²ä¸€è‡´æ€§æµ‹è¯•
    print("ğŸ­ è§’è‰²ä¸€è‡´æ€§æµ‹è¯•...")
    roles = ['creator', 'analyst', 'critic', 'synthesizer']
    role_scores = {}
    role_explanations = {}
    
    for role in roles:
        print(f"   æµ‹è¯•è§’è‰²: {role}")
        score, explanation = test_role_consistency_explained(service_name, model_name, role, scorer)
        role_scores[role] = score
        role_explanations[role] = explanation
    
    avg_role_consistency = sum(role_scores.values()) / len(role_scores)
    
    # 4. è®¤çŸ¥å¤šæ ·æ€§æµ‹è¯•
    print("ğŸŒˆ è®¤çŸ¥å¤šæ ·æ€§æµ‹è¯•...")
    diversity_score, diversity_explanation = test_cognitive_diversity_explained(service_name, model_name, roles, scorer)
    
    # è®¡ç®—ç»¼åˆå¾—åˆ†
    overall_score = (hallucination_score + avg_role_consistency + diversity_score) / 3
    
    end_time = time.time()
    test_duration = end_time - start_time
    
    # ç”Ÿæˆè¯¦ç»†ç»“æœ
    result = {
        'model_name': f"{service_name}/{model_name}",
        'service_name': service_name,
        'model_display_name': model_name,
        'status': 'success',
        'test_duration': test_duration,
        'scores': {
            'hallucination_resistance': hallucination_score,
            'role_consistency': avg_role_consistency,
            'cognitive_diversity': diversity_score,
            'overall_score': overall_score
        },
        'detailed_role_scores': role_scores,
        'explanations': {
            'hallucination_test': hallucination_explanation,
            'role_consistency_tests': role_explanations,
            'cognitive_diversity_test': diversity_explanation
        },
        'test_timestamp': datetime.now().isoformat()
    }
    
    # æ˜¾ç¤ºç»¼åˆè¯„åˆ†è§£é‡Š
    print(f"\nğŸ“Š ç»¼åˆè¯„åˆ†è§£é‡Š:")
    print(f"   å¹»è§‰æŠµæŠ—: {hallucination_score:.3f}åˆ† - {hallucination_explanation.get('è¯„åˆ†åŸå› ', 'æ— è§£é‡Š')}")
    print(f"   è§’è‰²ä¸€è‡´æ€§: {avg_role_consistency:.3f}åˆ† - 4ä¸ªè§’è‰²çš„å¹³å‡å¾—åˆ†")
    print(f"   è®¤çŸ¥å¤šæ ·æ€§: {diversity_score:.3f}åˆ† - {diversity_explanation.get('è¯„åˆ†åŸå› ', 'æ— è§£é‡Š')}")
    print(f"   ç»¼åˆå¾—åˆ†: {overall_score:.3f}åˆ† - ä¸‰é¡¹æµ‹è¯•çš„å¹³å‡åˆ†")
    
    print(f"âœ… æµ‹è¯•å®Œæˆï¼Œè€—æ—¶: {test_duration:.2f}ç§’")
    
    return result

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§  å¯è§£é‡Šçš„è®¤çŸ¥ç”Ÿæ€ç³»ç»Ÿäº‘æ¨¡å‹æµ‹è¯•")
    print("=" * 50)
    print("ğŸ“‹ æœ¬æµ‹è¯•å°†è¯¦ç»†è§£é‡Šæ¯ä¸ªåˆ†æ•°çš„è®¡ç®—è¿‡ç¨‹å’Œè¯„åˆ†ä¾æ®")
    
    # é€‰æ‹©ä¸€ä¸ªæ¨¡å‹è¿›è¡Œè¯¦ç»†æµ‹è¯•æ¼”ç¤º
    test_models = [
        ('siliconflow', 'THUDM/glm-4-9b-chat'),
        ('ppinfra', 'qwen/qwen3-235b-a22b-fp8'),
        ('glm', 'glm-4-plus')
    ]
    
    print(f"\nğŸ“‹ å¯ç”¨æµ‹è¯•æ¨¡å‹:")
    for i, (service, model) in enumerate(test_models, 1):
        print(f"  {i}. {service}/{model}")
    
    choice = input(f"\nè¯·é€‰æ‹©è¦æµ‹è¯•çš„æ¨¡å‹ (1-{len(test_models)}ï¼Œé»˜è®¤1): ").strip() or "1"
    
    try:
        model_index = int(choice) - 1
        if 0 <= model_index < len(test_models):
            service_name, model_name = test_models[model_index]
        else:
            service_name, model_name = test_models[0]
    except ValueError:
        service_name, model_name = test_models[0]
    
    print(f"\nğŸ¯ å¼€å§‹æµ‹è¯•: {service_name}/{model_name}")
    
    # è¿è¡Œè¯¦ç»†æµ‹è¯•
    result = run_explainable_test(service_name, model_name)
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"explainable_cognitive_test_{timestamp}.json"
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“ è¯¦ç»†æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {filename}")
    print("ğŸ“– æ–‡ä»¶åŒ…å«å®Œæ•´çš„è¯„åˆ†è§£é‡Šå’Œè®¡ç®—è¿‡ç¨‹")

if __name__ == "__main__":
    main()
