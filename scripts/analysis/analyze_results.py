#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LLMæµ‹è¯„ç»“æœæ·±åº¦åˆ†æè„šæœ¬
æä¾›è¯¦ç»†çš„ç»Ÿè®¡åˆ†æã€è¶‹åŠ¿åˆ†æå’Œå¯¹æ¯”åˆ†æ
"""

import os
import re
import json
from datetime import datetime
from collections import defaultdict

class LLMResultAnalyzer:
    def __init__(self, testout_dir="testout"):
        self.testout_dir = testout_dir
        self.pillar_mapping = {
            "creativity": "Pillar 9: åˆ›æ„ç”Ÿæˆ",
            "math": "Pillar 10: æ•°å­¦æ¨ç†", 
            "safety": "Pillar 11: å®‰å…¨å¯¹é½",
            "persona": "Pillar 12: è§’è‰²æ‰®æ¼”",
            "init": "Pillar 13: æŒ‡ä»¤è§£æ",
            "persona_depth": "Pillar 14: è§’è‰²æ·±åº¦",
            "collaboration": "Pillar 15: åä½œèƒ½åŠ›",
            "emergence": "Pillar 16: æ¶Œç°åˆ†æ",
            "dag": "Pillar 17: å›¾è°±ç”Ÿæˆ",
            "fault_tolerance": "Pillar 18: å®¹é”™åè°ƒ",
            "network_analysis": "Pillar 19: ç½‘ç»œåˆ†æ"
        }
    
    def load_all_results(self):
        """åŠ è½½æ‰€æœ‰æµ‹è¯•ç»“æœ"""
        results = []
        
        if not os.path.exists(self.testout_dir):
            return results
            
        for filename in os.listdir(self.testout_dir):
            if not filename.endswith('.txt'):
                continue
                
            filepath = os.path.join(self.testout_dir, filename)
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # è§£ææ–‡ä»¶å†…å®¹
            result = self.parse_result_file(content, filename)
            if result:
                results.append(result)
        
        return results
    
    def parse_result_file(self, content, filename):
        """è§£æå•ä¸ªç»“æœæ–‡ä»¶"""
        lines = content.split('\n')
        result = {
            "filename": filename,
            "case_id": "",
            "type": "",
            "prompt": "",
            "response": "",
            "pillar": self.get_pillar_from_filename(filename)
        }
        
        current_section = None
        for line in lines:
            if line.startswith("ç”¨ä¾‹ç¼–å·:"):
                result["case_id"] = line.split(":", 1)[1].strip()
            elif line.startswith("ç±»å‹:"):
                result["type"] = line.split(":", 1)[1].strip()
            elif line.startswith("PROMPT:"):
                current_section = "prompt"
                continue
            elif line.startswith("MODEL RESPONSE"):
                current_section = "response"
                continue
            elif current_section == "prompt" and line.strip():
                result["prompt"] += line + "\n"
            elif current_section == "response" and line.strip():
                result["response"] += line + "\n"
        
        return result if result["response"].strip() else None
    
    def get_pillar_from_filename(self, filename):
        """ä»æ–‡ä»¶åæ¨æ–­Pillarç±»å‹"""
        for key in self.pillar_mapping:
            if key in filename:
                return key
        return "unknown"
    
    def analyze_response_quality(self, response):
        """åˆ†æå“åº”è´¨é‡çš„å¤šä¸ªç»´åº¦"""
        if not response:
            return {
                "length": 0,
                "sentence_count": 0,
                "avg_sentence_length": 0,
                "has_code": False,
                "has_structure": False,
                "completeness": 0
            }
        
        # åŸºæœ¬ç»Ÿè®¡
        length = len(response)
        sentences = response.count('ã€‚') + response.count('.') + response.count('!')
        avg_sentence_length = length / max(sentences, 1)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä»£ç 
        has_code = bool(re.search(r'```|`[^`]+`|#!/', response))
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æ„åŒ–å†…å®¹
        has_structure = bool(re.search(r'[1-9]\.|[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]ã€|##|###|\*\*', response))
        
        # å®Œæ•´æ€§è¯„ä¼°ï¼ˆç®€å•ç‰ˆæœ¬ï¼‰
        completeness = min(100, length / 50)  # å‡è®¾50å­—ç¬¦ä¸ºåŸºæœ¬å®Œæ•´
        
        return {
            "length": length,
            "sentence_count": sentences,
            "avg_sentence_length": avg_sentence_length,
            "has_code": has_code,
            "has_structure": has_structure,
            "completeness": completeness
        }
    
    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        results = self.load_all_results()
        
        if not results:
            return "é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•ç»“æœæ–‡ä»¶"
        
        # æŒ‰Pillaråˆ†ç»„ç»Ÿè®¡
        pillar_stats = defaultdict(list)
        for result in results:
            pillar_stats[result["pillar"]].append(result)
        
        report = f"""
# LLMæµ‹è¯„ç»“æœæ·±åº¦åˆ†ææŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**åˆ†ææ–‡ä»¶æ•°**: {len(results)}ä¸ª
**è¦†ç›–ç»´åº¦**: {len(pillar_stats)}ä¸ª

## ğŸ“Š æ•´ä½“è¡¨ç°æ¦‚è§ˆ

"""
        
        # æ•´ä½“ç»Ÿè®¡
        total_responses = len(results)
        valid_responses = len([r for r in results if r["response"].strip()])
        avg_response_length = sum(len(r["response"]) for r in results) / max(len(results), 1)
        
        report += f"""
### åŸºç¡€ç»Ÿè®¡
- **æ€»æµ‹è¯•æ¡ˆä¾‹**: {total_responses}
- **æœ‰æ•ˆå“åº”**: {valid_responses} ({valid_responses/total_responses*100:.1f}%)
- **å¹³å‡å“åº”é•¿åº¦**: {avg_response_length:.0f} å­—ç¬¦

"""
        
        # å„Pillarè¯¦ç»†åˆ†æ
        report += "## ğŸ” å„ç»´åº¦è¯¦ç»†åˆ†æ\n"
        
        for pillar, pillar_results in pillar_stats.items():
            if pillar == "unknown":
                continue
                
            pillar_name = self.pillar_mapping.get(pillar, pillar)
            report += f"\n### {pillar_name}\n"
            
            # ç»Ÿè®¡è¯¥Pillarçš„è¡¨ç°
            case_count = len(pillar_results)
            avg_length = sum(len(r["response"]) for r in pillar_results) / max(case_count, 1)
            
            # åˆ†æå“åº”è´¨é‡
            quality_stats = [self.analyze_response_quality(r["response"]) for r in pillar_results]
            avg_completeness = sum(q["completeness"] for q in quality_stats) / max(len(quality_stats), 1)
            code_ratio = sum(1 for q in quality_stats if q["has_code"]) / max(len(quality_stats), 1)
            structure_ratio = sum(1 for q in quality_stats if q["has_structure"]) / max(len(quality_stats), 1)
            
            report += f"""
- **æµ‹è¯•æ¡ˆä¾‹æ•°**: {case_count}
- **å¹³å‡å“åº”é•¿åº¦**: {avg_length:.0f} å­—ç¬¦
- **å®Œæ•´æ€§è¯„åˆ†**: {avg_completeness:.1f}/100
- **åŒ…å«ä»£ç æ¯”ä¾‹**: {code_ratio*100:.1f}%
- **ç»“æ„åŒ–å†…å®¹æ¯”ä¾‹**: {structure_ratio*100:.1f}%

**å…·ä½“æ¡ˆä¾‹**:
"""
            
            for result in pillar_results:
                quality = self.analyze_response_quality(result["response"])
                report += f"  - {result['type']}: {quality['length']}å­—ç¬¦, å®Œæ•´æ€§{quality['completeness']:.0f}%\n"
        
        # é—®é¢˜è¯†åˆ«
        report += "\n## âš ï¸ é—®é¢˜è¯†åˆ«ä¸åˆ†æ\n"
        
        # æ‰¾å‡ºé—®é¢˜æ¡ˆä¾‹
        short_responses = [r for r in results if len(r["response"]) < 50]
        empty_responses = [r for r in results if not r["response"].strip()]
        
        if empty_responses:
            report += f"\n### æ— å“åº”æ¡ˆä¾‹ ({len(empty_responses)}ä¸ª)\n"
            for r in empty_responses:
                report += f"- {r['filename']}: {r['type']}\n"
        
        if short_responses:
            report += f"\n### å“åº”è¿‡çŸ­æ¡ˆä¾‹ ({len(short_responses)}ä¸ª)\n"
            for r in short_responses:
                report += f"- {r['filename']}: {len(r['response'])}å­—ç¬¦\n"
        
        # æ”¹è¿›å»ºè®®
        report += "\n## ğŸ¯ æ”¹è¿›å»ºè®®\n"
        
        if len(empty_responses) > len(results) * 0.2:
            report += "- **ç´§æ€¥**: è¶…è¿‡20%çš„æµ‹è¯•æ— å“åº”ï¼Œå»ºè®®æ£€æŸ¥æ¨¡å‹é…ç½®å’Œç½‘ç»œè¿æ¥\n"
        
        if avg_response_length < 100:
            report += "- **é‡è¦**: å¹³å‡å“åº”é•¿åº¦è¿‡çŸ­ï¼Œå»ºè®®ä¼˜åŒ–æç¤ºè¯ä»¥è·å¾—æ›´è¯¦ç»†çš„å›ç­”\n"
        
        if code_ratio < 0.3:
            report += "- **å»ºè®®**: ä»£ç ç”Ÿæˆèƒ½åŠ›ä¸è¶³ï¼Œè€ƒè™‘åœ¨æç¤ºè¯ä¸­æ˜ç¡®è¦æ±‚ä»£ç è¾“å‡º\n"
        
        return report
    
    def save_analysis_data(self):
        """ä¿å­˜åˆ†ææ•°æ®ä¸ºJSONæ ¼å¼ï¼Œä¾¿äºè¿›ä¸€æ­¥å¤„ç†"""
        results = self.load_all_results()
        
        analysis_data = {
            "timestamp": datetime.now().isoformat(),
            "total_cases": len(results),
            "pillar_summary": {},
            "detailed_results": []
        }
        
        # æŒ‰Pillaræ±‡æ€»
        pillar_stats = defaultdict(list)
        for result in results:
            pillar_stats[result["pillar"]].append(result)
        
        for pillar, pillar_results in pillar_stats.items():
            if pillar == "unknown":
                continue
                
            analysis_data["pillar_summary"][pillar] = {
                "name": self.pillar_mapping.get(pillar, pillar),
                "case_count": len(pillar_results),
                "avg_response_length": sum(len(r["response"]) for r in pillar_results) / max(len(pillar_results), 1),
                "cases": [r["type"] for r in pillar_results]
            }
        
        # è¯¦ç»†ç»“æœ
        for result in results:
            quality = self.analyze_response_quality(result["response"])
            analysis_data["detailed_results"].append({
                "filename": result["filename"],
                "pillar": result["pillar"],
                "type": result["type"],
                "case_id": result["case_id"],
                "quality_metrics": quality
            })
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open("analysis_data.json", 'w', encoding='utf-8') as f:
            json.dump(analysis_data, f, ensure_ascii=False, indent=2)
        
        return "analysis_data.json"

def main():
    analyzer = LLMResultAnalyzer()
    
    # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    report = analyzer.generate_comprehensive_report()
    
    # ä¿å­˜æŠ¥å‘Š
    with open("comprehensive_analysis_report.md", 'w', encoding='utf-8') as f:
        f.write(report)
    
    # ä¿å­˜åˆ†ææ•°æ®
    data_file = analyzer.save_analysis_data()
    
    print("æ·±åº¦åˆ†æå®Œæˆï¼")
    print("- ç»¼åˆæŠ¥å‘Š: comprehensive_analysis_report.md")
    print(f"- åˆ†ææ•°æ®: {data_file}")
    print("\n" + "="*50)
    print(report)

if __name__ == "__main__":
    main()
