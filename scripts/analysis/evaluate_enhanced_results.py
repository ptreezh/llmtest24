#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŠ å¼ºæµ‹è¯•ç»“æœè¯„ä»·è„šæœ¬
ä¸“é—¨è¯„ä»·æ¶Œç°åˆ†æã€æ•°å­¦æ¨ç†ã€è§’è‰²æ‰®æ¼”çš„åŠ å¼ºæµ‹è¯•ç»“æœ
"""

import os
import re
import json
from datetime import datetime
from typing import Dict, List, Tuple

class EnhancedResultsEvaluator:
    def __init__(self, testout_dir="testout_enhanced"):
        self.testout_dir = testout_dir
        self.evaluation_results = {}
    
    def load_test_result(self, filename: str) -> Dict:
        """åŠ è½½æµ‹è¯•ç»“æœæ–‡ä»¶"""
        filepath = os.path.join(self.testout_dir, filename)
        if not os.path.exists(filepath):
            return None
            
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()
        
        lines = content.split('\n')
        result = {
            "test_id": "",
            "type": "",
            "difficulty": "",
            "prompt": "",
            "response": ""
        }
        
        current_section = None
        for line in lines:
            if line.startswith("æµ‹è¯•ID:"):
                result["test_id"] = line.split(":", 1)[1].strip()
            elif line.startswith("ç±»å‹:"):
                result["type"] = line.split(":", 1)[1].strip()
            elif line.startswith("éš¾åº¦:"):
                result["difficulty"] = line.split(":", 1)[1].strip()
            elif line.startswith("PROMPT:"):
                current_section = "prompt"
                continue
            elif line.startswith("MODEL RESPONSE"):
                current_section = "response"
                continue
            elif current_section == "prompt" and line.strip():
                result["prompt"] += line + "\n"
            elif current_section == "response" and line.strip():
                result["response"] += line + "\n"
        
        return result
    
    def evaluate_enhanced_emergence(self, result: Dict) -> Tuple[int, str]:
        """è¯„ä»·åŠ å¼ºç‰ˆæ¶Œç°åˆ†æ"""
        response = result["response"].strip()
        if not response:
            return 0, "æ— å“åº”å†…å®¹"
        
        score = 0
        feedback = []
        max_score = 15  # åŠ å¼ºæµ‹è¯•æé«˜æ»¡åˆ†
        
        # 1. å¤šç»´åº¦å†²çªè¯†åˆ« (4åˆ†)
        conflict_keywords = ["å†²çª", "çŸ›ç›¾", "å¯¹ç«‹", "æ‚–è®º", "ä¸¤éš¾", "å›°å¢ƒ"]
        if any(word in response for word in conflict_keywords):
            score += 4
            feedback.append("âœ“ è¯†åˆ«äº†å¤æ‚å†²çª")
        
        # 2. ç³»ç»Ÿæ€§åˆ†æ (4åˆ†)
        analysis_indicators = response.count("æ–¹é¢") + response.count("ç»´åº¦") + response.count("è§’åº¦")
        if analysis_indicators >= 3:
            score += 4
            feedback.append("âœ“ è¿›è¡Œäº†å¤šç»´åº¦ç³»ç»Ÿåˆ†æ")
        elif analysis_indicators >= 1:
            score += 2
            feedback.append("âš  åˆ†æç»´åº¦æœ‰é™")
        
        # 3. åˆ›æ–°æ€§è§£å†³æ–¹æ¡ˆ (4åˆ†)
        innovation_keywords = ["åˆ›æ–°", "çªç ´", "ç¬¬ä¸‰æ¡é“è·¯", "æ•´åˆ", "å¹³è¡¡", "åŒèµ¢", "å¤šèµ¢"]
        innovation_count = sum(1 for word in innovation_keywords if word in response)
        if innovation_count >= 3:
            score += 4
            feedback.append("âœ“ æå‡ºäº†é«˜åº¦åˆ›æ–°çš„è§£å†³æ–¹æ¡ˆ")
        elif innovation_count >= 1:
            score += 2
            feedback.append("âš  è§£å†³æ–¹æ¡ˆæœ‰ä¸€å®šåˆ›æ–°æ€§")
        
        # 4. å®æ–½å¯è¡Œæ€§ (3åˆ†)
        feasibility_keywords = ["æ­¥éª¤", "é˜¶æ®µ", "ä¼˜å…ˆçº§", "æ—¶é—´", "èµ„æº", "é¢„ç®—", "å›¢é˜Ÿ"]
        if any(word in response for word in feasibility_keywords):
            score += 3
            feedback.append("âœ“ è€ƒè™‘äº†å®æ–½å¯è¡Œæ€§")
        
        return min(score, max_score), "; ".join(feedback)
    
    def evaluate_enhanced_math(self, result: Dict) -> Tuple[int, str]:
        """è¯„ä»·åŠ å¼ºç‰ˆæ•°å­¦æ¨ç†"""
        response = result["response"].strip()
        if not response:
            return 0, "æ— å“åº”å†…å®¹"
        
        score = 0
        feedback = []
        max_score = 15  # åŠ å¼ºæµ‹è¯•æé«˜æ»¡åˆ†
        
        # 1. é—®é¢˜ç†è§£å’Œå»ºæ¨¡ (4åˆ†)
        modeling_keywords = ["å˜é‡", "çº¦æŸ", "ç›®æ ‡å‡½æ•°", "æ¨¡å‹", "å‡è®¾"]
        if any(word in response for word in modeling_keywords):
            score += 4
            feedback.append("âœ“ æ­£ç¡®ç†è§£å¹¶å»ºæ¨¡é—®é¢˜")
        
        # 2. æ•°å­¦è®¡ç®—è¿‡ç¨‹ (5åˆ†)
        calculation_indicators = [
            response.count("="),
            response.count("è®¡ç®—"),
            response.count("å…¬å¼"),
            len(re.findall(r'\d+\.?\d*', response))
        ]
        total_calc_indicators = sum(calculation_indicators)
        
        if total_calc_indicators >= 10:
            score += 5
            feedback.append("âœ“ åŒ…å«è¯¦ç»†çš„è®¡ç®—è¿‡ç¨‹")
        elif total_calc_indicators >= 5:
            score += 3
            feedback.append("âš  è®¡ç®—è¿‡ç¨‹è¾ƒç®€å•")
        elif total_calc_indicators >= 2:
            score += 1
            feedback.append("âš  è®¡ç®—è¿‡ç¨‹ä¸è¶³")
        
        # 3. é€»è¾‘æ¨ç† (3åˆ†)
        reasoning_keywords = ["å› ä¸º", "æ‰€ä»¥", "æ¨å¯¼", "è¯æ˜", "ç»“è®º"]
        if any(word in response for word in reasoning_keywords):
            score += 3
            feedback.append("âœ“ å±•ç°äº†é€»è¾‘æ¨ç†è¿‡ç¨‹")
        
        # 4. ç»“æœéªŒè¯å’Œè§£é‡Š (3åˆ†)
        validation_keywords = ["éªŒè¯", "æ£€æŸ¥", "åˆç†æ€§", "æ„ä¹‰", "è§£é‡Š"]
        if any(word in response for word in validation_keywords):
            score += 3
            feedback.append("âœ“ å¯¹ç»“æœè¿›è¡Œäº†éªŒè¯å’Œè§£é‡Š")
        
        return min(score, max_score), "; ".join(feedback)
    
    def evaluate_enhanced_persona(self, result: Dict) -> Tuple[int, str]:
        """è¯„ä»·åŠ å¼ºç‰ˆè§’è‰²æ‰®æ¼”"""
        response = result["response"].strip()
        if not response:
            return 0, "æ— å“åº”å†…å®¹"
        
        score = 0
        feedback = []
        max_score = 15  # åŠ å¼ºæµ‹è¯•æé«˜æ»¡åˆ†
        
        # 1. è§’è‰²ç‰¹å¾ä½“ç° (4åˆ†)
        # æ ¹æ®ä¸åŒè§’è‰²æ£€æŸ¥ç‰¹å¾è¯æ±‡
        test_id = result.get("test_id", "")
        
        if "persona_advanced_1" in test_id:  # æŠ•èµ„é¡¾é—®
            role_keywords = ["é£é™©", "æ”¶ç›Š", "æŠ•èµ„", "èµ„äº§", "é…ç½®", "å¸‚åœº"]
        elif "persona_advanced_2" in test_id:  # å¤ä»£è°‹å£«
            role_keywords = ["ä¸»å…¬", "ç­–ç•¥", "å…µæ³•", "å¤©ä¸‹", "å›ä¸»", "è‡£"]
        elif "persona_advanced_3" in test_id:  # AIä¼¦ç†å­¦å®¶
            role_keywords = ["ä¼¦ç†", "æŠ€æœ¯", "äººç±»", "ç¤¾ä¼š", "æœªæ¥", "è´£ä»»"]
        else:
            role_keywords = ["ä¸“ä¸š", "ç»éªŒ", "å»ºè®®"]
        
        role_match_count = sum(1 for word in role_keywords if word in response)
        if role_match_count >= 3:
            score += 4
            feedback.append("âœ“ å¼ºçƒˆä½“ç°äº†è§’è‰²ç‰¹å¾")
        elif role_match_count >= 1:
            score += 2
            feedback.append("âš  éƒ¨åˆ†ä½“ç°äº†è§’è‰²ç‰¹å¾")
        
        # 2. ä¸“ä¸šçŸ¥è¯†æ·±åº¦ (4åˆ†)
        depth_indicators = [
            len(response) > 200,  # å›ç­”è¯¦ç»†
            response.count("ã€‚") >= 3,  # å¤šä¸ªè§‚ç‚¹
            "ä¾‹å¦‚" in response or "æ¯”å¦‚" in response,  # ä¸¾ä¾‹è¯´æ˜
            any(word in response for word in ["ç»éªŒ", "æ¡ˆä¾‹", "å†å²", "æ•°æ®"])  # ä¸“ä¸šèƒŒæ™¯
        ]
        depth_score = sum(depth_indicators)
        score += depth_score
        if depth_score >= 3:
            feedback.append("âœ“ å±•ç°äº†æ·±åšçš„ä¸“ä¸šçŸ¥è¯†")
        elif depth_score >= 1:
            feedback.append("âš  ä¸“ä¸šçŸ¥è¯†æœ‰é™")
        
        # 3. è¯­è¨€é£æ ¼ä¸€è‡´æ€§ (4åˆ†)
        if "persona_advanced_2" in test_id:  # å¤ä»£è°‹å£«éœ€è¦æ–‡è¨€é£æ ¼
            classical_indicators = ["ä¹‹", "è€…", "ä¹Ÿ", "çŸ£", "ä¹", "ç„‰"]
            if any(word in response for word in classical_indicators):
                score += 4
                feedback.append("âœ“ ä¿æŒäº†å¤å…¸è¯­è¨€é£æ ¼")
            else:
                feedback.append("âš  è¯­è¨€é£æ ¼ä¸å¤Ÿå¤å…¸")
        else:
            # å…¶ä»–è§’è‰²æ£€æŸ¥ä¸“ä¸šæœ¯è¯­ä½¿ç”¨
            if role_match_count >= 2:
                score += 4
                feedback.append("âœ“ è¯­è¨€é£æ ¼ç¬¦åˆè§’è‰²")
            else:
                score += 2
                feedback.append("âš  è¯­è¨€é£æ ¼ä¸€èˆ¬")
        
        # 4. æƒ…å¢ƒé€‚åº”æ€§ (3åˆ†)
        context_keywords = ["æ ¹æ®", "è€ƒè™‘åˆ°", "åœ¨è¿™ç§æƒ…å†µä¸‹", "é’ˆå¯¹", "å…·ä½“"]
        if any(word in response for word in context_keywords):
            score += 3
            feedback.append("âœ“ å¾ˆå¥½åœ°é€‚åº”äº†æƒ…å¢ƒ")
        
        return min(score, max_score), "; ".join(feedback)
    
    def generate_enhanced_report(self) -> str:
        """ç”ŸæˆåŠ å¼ºæµ‹è¯•è¯„ä»·æŠ¥å‘Š"""
        if not os.path.exists(self.testout_dir):
            return "é”™è¯¯: åŠ å¼ºæµ‹è¯•ç»“æœç›®å½•ä¸å­˜åœ¨"
        
        results = []
        
        # åŠ è½½æ‰€æœ‰æµ‹è¯•ç»“æœ
        for filename in os.listdir(self.testout_dir):
            if not filename.endswith('.txt'):
                continue
            
            result = self.load_test_result(filename)
            if not result:
                continue
            
            # æ ¹æ®æµ‹è¯•ç±»å‹è¿›è¡Œè¯„ä»·
            if 'emergence' in filename:
                score, feedback = self.evaluate_enhanced_emergence(result)
                category = "æ¶Œç°åˆ†æ"
                max_score = 15
            elif 'math' in filename:
                score, feedback = self.evaluate_enhanced_math(result)
                category = "æ•°å­¦æ¨ç†"
                max_score = 15
            elif 'persona' in filename:
                score, feedback = self.evaluate_enhanced_persona(result)
                category = "è§’è‰²æ‰®æ¼”"
                max_score = 15
            else:
                continue
            
            results.append({
                "filename": filename,
                "category": category,
                "score": score,
                "max_score": max_score,
                "feedback": feedback,
                "test_id": result["test_id"],
                "type": result["type"],
                "difficulty": result["difficulty"]
            })
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        category_stats = {}
        for result in results:
            cat = result["category"]
            if cat not in category_stats:
                category_stats[cat] = {"scores": [], "total": 0, "count": 0, "max_total": 0}
            category_stats[cat]["scores"].append(result["score"])
            category_stats[cat]["total"] += result["score"]
            category_stats[cat]["max_total"] += result["max_score"]
            category_stats[cat]["count"] += 1
        
        # ç”ŸæˆæŠ¥å‘Š
        total_score = sum(r["score"] for r in results)
        max_total_score = sum(r["max_score"] for r in results)
        overall_percentage = total_score/max_total_score*100 if max_total_score > 0 else 0
        
        report = f"""
# è¡¨ç°æœ€å¥½çš„ä¸‰é¡¹èƒ½åŠ›åŠ å¼ºæµ‹è¯•è¯„ä»·æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**æ€»ä½“å¾—åˆ†**: {total_score}/{max_total_score} ({overall_percentage:.1f}%)
**æµ‹è¯•éš¾åº¦**: é«˜éš¾åº¦/æé«˜éš¾åº¦æŒ‘æˆ˜

## ğŸ“Š å„ç»´åº¦åŠ å¼ºæµ‹è¯•è¡¨ç°

"""
        
        for category, stats in category_stats.items():
            avg_score = stats["total"] / stats["count"]
            percentage = (stats["total"] / stats["max_total"]) * 100
            
            if percentage >= 80:
                status = "ğŸŒŸ å“è¶Š"
            elif percentage >= 60:
                status = "âœ… ä¼˜ç§€"
            elif percentage >= 40:
                status = "âš ï¸ ä¸­ç­‰"
            else:
                status = "âŒ éœ€æ”¹è¿›"
            
            report += f"""
### {category}
- **å¹³å‡å¾—åˆ†**: {avg_score:.1f}/15 ({percentage:.1f}%)
- **æµ‹è¯•æ¡ˆä¾‹**: {stats['count']}ä¸ª
- **è¡¨ç°ç­‰çº§**: {status}
"""
        
        report += "\n## ğŸ“‹ è¯¦ç»†æµ‹è¯•ç»“æœ\n"
        
        # æŒ‰ç±»åˆ«åˆ†ç»„æ˜¾ç¤ºç»“æœ
        for category in category_stats.keys():
            report += f"\n### {category}è¯¦ç»†ç»“æœ\n"
            category_results = [r for r in results if r["category"] == category]
            
            for result in category_results:
                percentage = result["score"] / result["max_score"] * 100
                report += f"""
#### {result['type']} (éš¾åº¦: {result['difficulty']})
- **å¾—åˆ†**: {result['score']}/{result['max_score']} ({percentage:.1f}%)
- **è¯„ä»·**: {result['feedback']}
- **æ–‡ä»¶**: {result['filename']}

"""
        
        # æ·»åŠ å¯¹æ¯”åˆ†æ
        report += "\n## ğŸ” ä¸åŸºç¡€æµ‹è¯•å¯¹æ¯”åˆ†æ\n"
        
        report += """
### åŸºç¡€æµ‹è¯• vs åŠ å¼ºæµ‹è¯•å¯¹æ¯”

| ç»´åº¦ | åŸºç¡€æµ‹è¯•å¾—åˆ† | åŠ å¼ºæµ‹è¯•å¾—åˆ† | éš¾åº¦æå‡ | è¡¨ç°å˜åŒ– |
|------|-------------|-------------|----------|----------|
| æ¶Œç°åˆ†æ | 10/10 (100%) | å¾…è®¡ç®— | é«˜â†’æé«˜ | å¾…åˆ†æ |
| æ•°å­¦æ¨ç† | 8.5/10 (85%) | å¾…è®¡ç®— | ä¸­â†’é«˜ | å¾…åˆ†æ |
| è§’è‰²æ‰®æ¼” | 5.5/10 (55%) | å¾…è®¡ç®— | ä¸­â†’æé«˜ | å¾…åˆ†æ |

### å…³é”®å‘ç°
1. **éš¾åº¦å‡çº§æ•ˆæœ**: æµ‹è¯•éš¾åº¦ä»ä¸­ç­‰æå‡åˆ°é«˜/æé«˜éš¾åº¦
2. **èƒ½åŠ›è¾¹ç•Œæ¢ç´¢**: æ¢ç´¢äº†æ¨¡å‹åœ¨å¤æ‚åœºæ™¯ä¸‹çš„è¡¨ç°ä¸Šé™
3. **ç¨³å®šæ€§éªŒè¯**: éªŒè¯äº†ä¼˜åŠ¿èƒ½åŠ›åœ¨é«˜éš¾åº¦ä¸‹çš„ç¨³å®šæ€§
"""
        
        return report

def main():
    evaluator = EnhancedResultsEvaluator()
    report = evaluator.generate_enhanced_report()
    
    # ä¿å­˜æŠ¥å‘Š
    with open("enhanced_evaluation_report.md", 'w', encoding='utf-8') as f:
        f.write(report)
    
    print("åŠ å¼ºæµ‹è¯•è¯„ä»·æŠ¥å‘Šå·²ç”Ÿæˆ: enhanced_evaluation_report.md")
    print("\n" + "="*50)
    print(report)

if __name__ == "__main__":
    main()
