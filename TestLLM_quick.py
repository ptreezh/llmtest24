#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿæµ‹è¯•ç‰ˆæœ¬ - éªŒè¯ä¿®æ”¹åçš„TestLLM.pyåŠŸèƒ½
åªæµ‹è¯•ä¸€ä¸ªæ¡ˆä¾‹ï¼Œä¸€ä¸ªæ¨¡å‹ï¼Œç”¨äºå¿«é€ŸéªŒè¯
"""

import requests
import random
import time
import os
import string
import csv
import tiktoken
from typing import Dict, Any

# --- CONFIGURATION ---
OLLAMA_API_URL = 'http://localhost:11434/api/chat'
# åªæµ‹è¯•ä¸€ä¸ªæ¨¡å‹è¿›è¡Œå¿«é€ŸéªŒè¯
MODELS_TO_TEST = ['atlas/intersync-gemma-7b-instruct-function-calling:latest']
MAX_CONTEXT_TOKENS = 8192
NUM_TEST_CASES = 1  # åªæµ‹è¯•ä¸€ä¸ªæ¡ˆä¾‹
TOTAL_TURNS_PER_CASE = 500  # å‡å°‘å¯¹è¯è½®æ•°ä»¥åŠ å¿«æµ‹è¯•
API_TIMEOUT = 300  # å‡å°‘è¶…æ—¶æ—¶é—´

def call_ollama(model: str, prompt: str, temperature: float = 0.7) -> str:
    """è°ƒç”¨Ollama API"""
    payload = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}],
        "stream": False,
        "options": {"temperature": temperature}
    }
    
    try:
        print(f"    - Calling model: {model}...")
        response = requests.post(OLLAMA_API_URL, json=payload, timeout=API_TIMEOUT)
        response.raise_for_status()
        
        response_data = response.json()
        content = response_data.get('message', {}).get('content', '')
        
        if not content:
            print(f"    âš ï¸ é›¶å“åº”è­¦å‘Š: æ¨¡å‹ {model} è¿”å›ç©ºå†…å®¹")
            return ""
        
        print(f"    âœ… å“åº”æˆåŠŸ: {len(content)}å­—ç¬¦")
        return content
        
    except requests.exceptions.Timeout:
        error_msg = f"[API Error: Timeout after {API_TIMEOUT}s for model {model}]"
        print(f"    âŒ è¶…æ—¶é”™è¯¯: {model}")
        return error_msg
    except Exception as e:
        error_msg = f"[API Error: {str(e)} for model {model}]"
        print(f"    âŒ APIé”™è¯¯: {str(e)}")
        return error_msg

def generate_case_script(case_num: int) -> Dict[str, Any]:
    """ç”Ÿæˆæ¡ˆä¾‹è„šæœ¬"""
    killers = ["A", "B", "C"]
    killer = random.choice(killers)
    
    motives = {
        "A": {
            "motive_desc": "å› å•†ä¸šç«äº‰è€Œä¸‹æ¯’",
            "strong_clues": [
                "æ¡ˆå‘ç°åœºå‘ç°äº†Aç‹¬æœ‰çš„ç‰¹æ®Šæ¯’è¯æ®‹ç•™",
                "Aåœ¨æ¡ˆå‘å‰è´­ä¹°äº†å¤§é‡ç›¸å…³åŒ–å­¦å“",
                "æœ‰ç›®å‡»è€…çœ‹åˆ°Aåœ¨å—å®³è€…é¥®å“ä¸­æŠ•æ”¾ç‰©è´¨"
            ],
            "red_herrings": [
                "å½“æ™šæœ‰äººå¬åˆ°äº†å¥‡æ€ªçš„éŸ³ä¹å£°",
                "å—å®³è€…æœ€è¿‘æ”¶åˆ°äº†åŒ¿åå¨èƒä¿¡",
                "ç°åœºå‘ç°äº†ä¸æ˜æŒ‡çº¹"
            ]
        },
        "B": {
            "motive_desc": "å› æœ¨æåˆ©æ¶¦çº çº·è€Œè¡Œå‡¶",
            "strong_clues": [
                "æ¡ˆå‘ç°åœºå‘ç°äº†ç¨€æœ‰çš„æ¾æœ¨ç¢å±‘ï¼Œåªæœ‰ä¼æœ¨å·¥ B ä¼šæ¥è§¦è¿™ç§æœ¨æ",
                "B çš„æ–§å¤´æœ€è¿‘è¢«å¼‚å¸¸ä»”ç»†åœ°æ‰“ç£¨å’Œæ¸…æ´—è¿‡",
                "æœ‰æ‘æ°‘å¬åˆ° B åœ¨æ¡ˆå‘å‰æ™šå¯¹å—å®³è€…å’†å“®è¯´'è¿™æ˜¯ä½ æœ€åä¸€æ¬¡äº¤è´§'"
            ],
            "red_herrings": [
                "å½“æ™šæœ‰äººå¬åˆ°äº†å¥‡æ€ªçš„é‡å…½åšå«å£°",
                "ä¸€ä¸ªå¸¸åœ¨æ²³è¾¹æ•£æ­¥çš„æ‘æ°‘çœ‹åˆ°ä¸€ä¸ªæ¨¡ç³Šçš„é»‘å½±è·³å…¥æ°´ä¸­",
                "å—å®³è€…æœ€è¿‘ä¼¼ä¹ä¸­äº†ä¸€ç¬”å°å½©ç¥¨ï¼Œä½†å¾ˆå¿«å°±èŠ±å…‰äº†"
            ]
        },
        "C": {
            "motive_desc": "å› æ„Ÿæƒ…çº çº·è€ŒæŠ¥å¤",
            "strong_clues": [
                "Cçš„æ—¥è®°ä¸­è¯¦ç»†è®°å½•äº†å¯¹å—å®³è€…çš„æ€¨æ¨",
                "æ¡ˆå‘ç°åœºå‘ç°äº†Cçš„ä¸ªäººç‰©å“",
                "Cåœ¨æ¡ˆå‘æ—¶é—´æ²¡æœ‰ä¸åœ¨åœºè¯æ˜"
            ],
            "red_herrings": [
                "ç°åœºå‘ç°äº†é™Œç”Ÿçš„è„šå°",
                "å—å®³è€…æœ€è¿‘è¡Œä¸ºå¼‚å¸¸",
                "é‚»å±…å¬åˆ°äº†äº‰åµå£°ä½†ä¸ç¡®å®šæ˜¯è°"
            ]
        }
    }
    
    script = motives[killer]
    return {
        "true_killer": killer,
        "motive": script["motive_desc"],
        "strong_clues": script["strong_clues"],
        "weak_clues": script["red_herrings"],
        "all_clues": script["strong_clues"] + script["red_herrings"]
    }

def get_prompt(prompt_type: str, context: Dict[str, Any]) -> str:
    """ç”Ÿæˆæç¤ºè¯"""
    if prompt_type == "summary":
        return f"""
Please provide a concise summary of the following dialogue segment. Focus on key facts, clues, and important details that might be relevant to solving a mystery.

Dialogue segment:
---
{context['dialogue_segment']}
---

Previous summary (if any):
{context.get('previous_summary', 'None')}

Please provide an updated summary that incorporates both the previous summary and the new dialogue segment:
"""
    
    elif prompt_type == "final":
        return f"""
You are a detective analyzing a mystery case. Based on all the evidence and information gathered, please provide your final analysis and conclusion.

Summary of all evidence and information:
---
{context['summary_so_far']}
---

Please provide your final reasoning and identify who you believe is the perpetrator and why. Be specific about the evidence that supports your conclusion.
"""

def save_case_analysis(case_num: int, model: str, script: Dict[str, Any], final_reasoning: str):
    """ä¿å­˜æ¡ˆä¾‹åˆ†ææŠ¥å‘Š"""
    # æ£€æŸ¥æ¨¡å‹å“åº”è´¨é‡
    if not final_reasoning or final_reasoning.strip() == "":
        reasoning_status = "âŒ æ¨¡å‹æœªæä¾›åˆ†æ (é›¶å“åº”é—®é¢˜)"
        reasoning_content = "æ— å“åº”å†…å®¹"
    elif "[API Error:" in final_reasoning:
        reasoning_status = "âŒ APIè°ƒç”¨é”™è¯¯"
        reasoning_content = final_reasoning
    else:
        reasoning_status = "âœ… æ¨¡å‹æä¾›äº†åˆ†æ"
        reasoning_content = final_reasoning
    
    analysis_report = f"""
=== æ¡ˆä¾‹ {case_num} åˆ†ææŠ¥å‘Š ===
æ¨¡å‹: {model}
æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}
çŠ¶æ€: {reasoning_status}

--- æ¨¡å‹åŸå§‹åˆ†æ ---
{reasoning_content}

--- æ­£ç¡®ç­”æ¡ˆä¸è¯„åˆ¤æ ‡å‡† ---
âœ… æ­£ç¡®å‡¶æ‰‹: {script['true_killer']}
âœ… ä½œæ¡ˆåŠ¨æœº: {script['motive']}

âœ… å…³é”®è¯æ® (å¼ºçº¿ç´¢):
{chr(10).join(f"  â€¢ {clue}" for clue in script['strong_clues'])}

âš ï¸ å¹²æ‰°ä¿¡æ¯ (å¼±çº¿ç´¢):
{chr(10).join(f"  â€¢ {clue}" for clue in script['weak_clues'])}

ğŸ“‹ è¯„åˆ¤æ ‡å‡†:
1. å‡¶æ‰‹è¯†åˆ« (æ˜¯å¦æ­£ç¡®æŒ‡å‡º {script['true_killer']})
2. è¯æ®ä½¿ç”¨ (æ˜¯å¦æœ‰æ•ˆåˆ©ç”¨å…³é”®è¯æ®)
3. é€»è¾‘æ¨ç† (æ¨ç†é“¾æ˜¯å¦æ¸…æ™°è¿è´¯)
4. å¹²æ‰°æ’é™¤ (æ˜¯å¦è¢«å¼±çº¿ç´¢è¯¯å¯¼)

--- æ¨ç†è¦ç‚¹ ---
æ­£ç¡®çš„æ¨ç†åº”è¯¥:
â€¢ é‡ç‚¹å…³æ³¨å¼ºçº¿ç´¢ï¼Œå®ƒä»¬ç›´æ¥æŒ‡å‘çœŸå‡¶
â€¢ è¯†åˆ«å¹¶æ’é™¤å¹²æ‰°ä¿¡æ¯
â€¢ å»ºç«‹æ¸…æ™°çš„å› æœå…³ç³»é“¾
â€¢ å¾—å‡ºæ˜ç¡®çš„ç»“è®º

--- æ‰‹åŠ¨è¯„åˆ¤æŒ‡å— ---
è¯·æ ¹æ®ä»¥ä¸Šæ ‡å‡†å¯¹æ¨¡å‹åˆ†æè¿›è¡Œè¯„åˆ† (1-5åˆ†):
â–¡ å‡¶æ‰‹è¯†åˆ«: ___/5 (æ˜¯å¦æ­£ç¡®è¯†åˆ«å‡º {script['true_killer']})
â–¡ è¯æ®ä½¿ç”¨: ___/5 (æ˜¯å¦æœ‰æ•ˆä½¿ç”¨å¼ºçº¿ç´¢)
â–¡ é€»è¾‘æ¨ç†: ___/5 (æ¨ç†æ˜¯å¦æ¸…æ™°è¿è´¯)
â–¡ å¹²æ‰°æ’é™¤: ___/5 (æ˜¯å¦é¿å…è¢«å¼±çº¿ç´¢è¯¯å¯¼)
â–¡ æ€»ä½“è¯„åˆ†: ___/5

===============================
"""
    
    filename = f"quick_test_case_{case_num}_{model.replace('/', '_').replace(':', '_')}_analysis.txt"
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(analysis_report)
    
    print(f"    âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {filename}")
    return analysis_report

def run_quick_test():
    """è¿è¡Œå¿«é€Ÿæµ‹è¯•"""
    print("ğŸš€ å¿«é€Ÿæµ‹è¯•å¼€å§‹")
    print("="*50)
    
    results = []
    
    for i in range(NUM_TEST_CASES):
        print(f"\n--- è¿è¡Œæµ‹è¯•æ¡ˆä¾‹ {i + 1}/{NUM_TEST_CASES} ---")
        
        # ç”Ÿæˆæ¡ˆä¾‹
        script = generate_case_script(i + 1)
        print(f"  - æ¡ˆä¾‹ç”Ÿæˆå®Œæˆ. å‡¶æ‰‹: {script['true_killer']}")
        
        # ç”Ÿæˆç®€åŒ–çš„å¯¹è¯å†…å®¹
        dialogue_content = f"""
ä¾¦æ¢è°ƒæŸ¥è®°å½• - æ¡ˆä¾‹ {i + 1}

ç°åœºå‹˜æŸ¥:
{chr(10).join(f"- {clue}" for clue in script['all_clues'])}

å«Œç–‘äººä¿¡æ¯:
- å«Œç–‘äººA: å•†äººï¼Œä¸å—å®³è€…æœ‰å•†ä¸šå¾€æ¥
- å«Œç–‘äººB: ä¼æœ¨å·¥ï¼Œä¸å—å®³è€…æœ‰åˆä½œå…³ç³»  
- å«Œç–‘äººC: é‚»å±…ï¼Œä¸å—å®³è€…å…³ç³»å¤æ‚

è°ƒæŸ¥è¿›å±•:
ç»è¿‡è¯¦ç»†è°ƒæŸ¥ï¼Œå‘ç°äº†å¤šæ¡çº¿ç´¢ã€‚éœ€è¦ä»”ç»†åˆ†æå“ªäº›æ˜¯å…³é”®è¯æ®ï¼Œå“ªäº›å¯èƒ½æ˜¯å¹²æ‰°ä¿¡æ¯ã€‚
"""
        
        # ä½¿ç”¨tiktokenè®¡ç®—tokenæ•°
        encoding = tiktoken.get_encoding("cl100k_base")
        dialogue_tokens = encoding.encode(dialogue_content)
        print(f"  - å¯¹è¯å†…å®¹ç”Ÿæˆå®Œæˆ. æ€»tokens: {len(dialogue_tokens)}")
        
        for model in MODELS_TO_TEST:
            print(f"\n  æµ‹è¯•æ¨¡å‹: {model}, ç­–ç•¥: Balanced-4k")
            
            # å¹³è¡¡ç­–ç•¥å¤„ç†
            breakpoint = int(MAX_CONTEXT_TOKENS * 0.5)  # 4096
            
            if len(dialogue_tokens) <= breakpoint:
                # ç›´æ¥å¤„ç†
                print(f"    - ç›´æ¥å¤„ç†: {len(dialogue_tokens)} tokens")
                summary_prompt = get_prompt("summary", {
                    "dialogue_segment": dialogue_content,
                    "previous_summary": ""
                })
                last_summary = call_ollama(model, summary_prompt)
            else:
                # åˆ†æ®µå¤„ç†
                print(f"    - åˆ†æ®µå¤„ç†: æ®µ1 (0 åˆ° {breakpoint})")
                segment1 = encoding.decode(dialogue_tokens[:breakpoint])
                summary_prompt1 = get_prompt("summary", {
                    "dialogue_segment": segment1,
                    "previous_summary": ""
                })
                summary1 = call_ollama(model, summary_prompt1)
                
                print(f"    - åˆ†æ®µå¤„ç†: æ®µ2 ({breakpoint} åˆ° {len(dialogue_tokens)})")
                segment2 = encoding.decode(dialogue_tokens[breakpoint:])
                summary_prompt2 = get_prompt("summary", {
                    "dialogue_segment": segment2,
                    "previous_summary": summary1
                })
                last_summary = call_ollama(model, summary_prompt2)
            
            # æœ€ç»ˆæ¨ç†
            if "[API Error:" in last_summary:
                final_reasoning = last_summary
            else:
                print("    - ç”Ÿæˆæœ€ç»ˆæ¨ç†...")
                final_prompt = get_prompt("final", {"summary_so_far": last_summary})
                final_reasoning = call_ollama(model, final_prompt)
            
            # ä¿å­˜åˆ†ææŠ¥å‘Š
            if "[API Error:" not in final_reasoning:
                print("    - ä¿å­˜åˆ†ææŠ¥å‘Š...")
                save_case_analysis(i + 1, model, script, final_reasoning)
            
            # è®°å½•ç»“æœ
            if not final_reasoning or final_reasoning.strip() == "":
                response_status = "zero_response"
            elif "[API Error:" in final_reasoning:
                response_status = "api_error"
            else:
                response_status = "success"
            
            result = {
                "test_case": i + 1,
                "model": model,
                "strategy": "Balanced-4k",
                "true_killer": script['true_killer'],
                "motive": script['motive'],
                "final_reasoning": final_reasoning,
                "response_status": response_status,
                "reasoning_length": len(final_reasoning) if final_reasoning else 0,
                "timestamp": time.strftime('%Y-%m-%d %H:%M:%S')
            }
            results.append(result)
    
    # ä¿å­˜CSVæŠ¥å‘Š
    if results:
        with open('quick_test_report.csv', 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=results[0].keys())
            writer.writeheader()
            writer.writerows(results)
    
    print(f"\n--- å¿«é€Ÿæµ‹è¯•å®Œæˆ ---")
    print(f"CSVæŠ¥å‘Š: quick_test_report.csv")
    print(f"è¯¦ç»†åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°å½“å‰ç›®å½•")

if __name__ == "__main__":
    run_quick_test()
