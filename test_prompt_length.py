#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•atlasæ¨¡å‹çš„æç¤ºè¯é•¿åº¦æ˜¯å¦ç¬¦åˆ<200å­—ç¬¦çš„è¦æ±‚
"""

def get_prompt(prompt_type: str, context: dict = {}, model: str = "") -> str:
    """å¤åˆ¶TestLLM.pyä¸­çš„get_promptå‡½æ•°è¿›è¡Œæµ‹è¯•"""
    # é’ˆå¯¹atlas/intersync-gemmaæ¨¡å‹çš„ä¼˜åŒ–æç¤ºè¯ï¼ˆæ€»é•¿åº¦<360å­—ç¬¦ï¼‰
    # ç³»ç»Ÿæç¤ºè¯(120) + ç”¨æˆ·æç¤ºè¯(<240) = 360å­—ç¬¦
    if "atlas/intersync-gemma" in model:
        if prompt_type == "intermediate":
            if context.get('summary_so_far', '').strip() and context.get('summary_so_far', '').strip() != 'None':
                # åŒ…å«ä»»åŠ¡+æ¦‚æ‹¬+æ–°å†…å®¹ï¼Œæ€»è®¡<240å­—ç¬¦ï¼ˆç³»ç»Ÿæç¤ºè¯115å­—ç¬¦ï¼‰
                task = "Find killer:"  # 12å­—ç¬¦ä»»åŠ¡è¯´æ˜
                summary = context['summary_so_far'][:100]  # 100å­—ç¬¦æ¦‚æ‹¬
                new_content = context['new_dialogue_chunk'][:80]  # 80å­—ç¬¦æ–°å†…å®¹
                return f"{task}\nEvidence: {summary}\nNew: {new_content}\nUpdate:"
            else:
                # åˆå§‹æç¤ºè¯ï¼šä»»åŠ¡+å†…å®¹
                task = "Find killer:"  # 12å­—ç¬¦ä»»åŠ¡è¯´æ˜
                content = context['new_dialogue_chunk'][:200]  # 200å­—ç¬¦å†…å®¹
                return f"{task}\nDialogue: {content}\nSummary:"
        elif prompt_type == "final":
            # æœ€ç»ˆæ¨ç†ï¼šä»»åŠ¡+æ¦‚æ‹¬
            task = "Find killer:"  # 12å­—ç¬¦ä»»åŠ¡è¯´æ˜
            facts = context.get('summary_so_far', '')[:200]  # 200å­—ç¬¦äº‹å®
            return f"{task}\nEvidence: {facts}\nAnswer:"

    return "Standard prompt for other models"

def test_prompt_lengths():
    """æµ‹è¯•å„ç§æƒ…å†µä¸‹çš„æç¤ºè¯é•¿åº¦"""
    print("ğŸ§ª Testing Atlas Model Prompt Lengths")
    print("="*50)
    
    model = "atlas/intersync-gemma-7b-instruct-function-calling:latest"
    system_prompt = "You are a detective analyzing a murder case. Summarize key evidence concisely. Focus on facts, clues, and suspects."

    print(f"System prompt: '{system_prompt}' ({len(system_prompt)} chars)")
    
    # æµ‹è¯•åœºæ™¯1ï¼šåˆå§‹æ‘˜è¦
    test_dialogue = "Aï¼šæ˜¨æ™šæˆ‘å¬åˆ°äº†å¥‡æ€ªçš„å£°éŸ³ã€‚Bï¼šæˆ‘ä¹Ÿå¬åˆ°äº†ï¼Œå¥½åƒæ˜¯ä»æ£®æ—ä¼ æ¥çš„ã€‚Cï¼šä¼šä¸ä¼šæ˜¯é‡å…½ï¼ŸDï¼šæˆ‘è§‰å¾—ä¸åƒï¼Œå£°éŸ³å¾ˆè§„å¾‹ã€‚"
    
    context1 = {
        "new_dialogue_chunk": test_dialogue
    }
    
    prompt1 = get_prompt("intermediate", context1, model)
    total1 = len(system_prompt) + len(prompt1)
    
    print(f"\n--- åœºæ™¯1ï¼šåˆå§‹æ‘˜è¦ ---")
    print(f"User prompt: '{prompt1}' ({len(prompt1)} chars)")
    print(f"Total length: {total1} chars")
    print(f"âœ… Within limit: {total1 < 200}")
    
    # æµ‹è¯•åœºæ™¯2ï¼šæ›´æ–°æ‘˜è¦
    previous_summary = "å¬åˆ°å¥‡æ€ªå£°éŸ³ï¼Œå¯èƒ½æ¥è‡ªæ£®æ—ï¼Œå£°éŸ³è§„å¾‹ä¸åƒé‡å…½"
    
    context2 = {
        "summary_so_far": previous_summary,
        "new_dialogue_chunk": test_dialogue
    }
    
    prompt2 = get_prompt("intermediate", context2, model)
    total2 = len(system_prompt) + len(prompt2)
    
    print(f"\n--- åœºæ™¯2ï¼šæ›´æ–°æ‘˜è¦ ---")
    print(f"User prompt: '{prompt2}' ({len(prompt2)} chars)")
    print(f"Total length: {total2} chars")
    print(f"âœ… Within limit: {total2 < 200}")
    
    # æµ‹è¯•åœºæ™¯3ï¼šæœ€ç»ˆæ¨ç†
    final_summary = "å¬åˆ°å¥‡æ€ªå£°éŸ³ï¼Œå‘ç°è„šå°ï¼Œå¼ ä¸‰ä¸¢æ–§å¤´ï¼Œé»‘å½±ä¸€ç±³å…«é«˜ï¼Œä¼æœ¨å·¥å¯ç–‘"
    
    context3 = {
        "summary_so_far": final_summary
    }
    
    prompt3 = get_prompt("final", context3, model)
    total3 = len(system_prompt) + len(prompt3)
    
    print(f"\n--- åœºæ™¯3ï¼šæœ€ç»ˆæ¨ç† ---")
    print(f"User prompt: '{prompt3}' ({len(prompt3)} chars)")
    print(f"Total length: {total3} chars")
    print(f"âœ… Within limit: {total3 < 200}")
    
    # æµ‹è¯•4000å­—æ€»ç»“å¸¦å…¥ä¸‹æ¬¡å¯¹è¯çš„æƒ…å†µ
    # æ¨¡æ‹Ÿç»è¿‡å¤šè½®4000 tokenså¤„ç†åçš„ç´¯ç§¯æ‘˜è¦
    accumulated_summary = "æ˜¨æ™šå¬åˆ°è§„å¾‹å£°éŸ³æ¥è‡ªæ£®æ—ï¼Œçœ‹åˆ°é»‘å½±åœ¨è€æ©¡æ ‘é™„è¿‘ç§»åŠ¨ï¼Œæ€€ç–‘æœ‰äººåšåäº‹ã€‚å¼ ä¸‰ä¸¢äº†æ–§å¤´å¯èƒ½æœ‰å…³ã€‚å‘ç°å¤§é´å­è„šå°ï¼Œæ­¥ä¼æ€¥ä¿ƒã€‚é»‘å½±èº«é«˜çº¦ä¸€ç±³å…«ã€‚åªæœ‰ä¼æœ¨å·¥ä¼šå»è€æ©¡æ ‘é‚£é‡Œï¼Œä½†æ·±å¤œå·¥ä½œä¸æ­£å¸¸ã€‚æ‘é‡Œç¬¦åˆèº«é«˜çš„äººä¸å¤šã€‚éœ€è¦è°ƒæŸ¥ä¼æœ¨å·¥çš„åŠ¨æœºå’Œè¡Œè¸ªã€‚"
    new_dialogue_segment = "Fï¼šæˆ‘æƒ³èµ·æ¥äº†ï¼Œæ˜¨å¤©çœ‹åˆ°æå››å¾ˆæ™šè¿˜åœ¨å¤–é¢ã€‚Gï¼šæå››ï¼Ÿä»–ä¸æ˜¯ä¼æœ¨å·¥å•Šã€‚Hï¼šä½†æ˜¯ä»–èº«é«˜ç¡®å®æœ‰ä¸€ç±³å…«ã€‚Iï¼šè€Œä¸”ä»–æœ€è¿‘å’Œå¼ ä¸‰æœ‰çŸ›ç›¾ã€‚"
    
    context4 = {
        "summary_so_far": accumulated_summary,
        "new_dialogue_chunk": new_dialogue_segment
    }
    
    prompt4 = get_prompt("intermediate", context4, model)
    total4 = len(system_prompt) + len(prompt4)
    
    print(f"\n--- åœºæ™¯4ï¼š4000å­—æ€»ç»“å¸¦å…¥ä¸‹æ¬¡å¯¹è¯ ---")
    print(f"User prompt: '{prompt4}' ({len(prompt4)} chars)")
    print(f"Total length: {total4} chars")
    print(f"âœ… Within limit: {total4 < 200}")

    # æµ‹è¯•åœºæ™¯5ï¼šæ¨¡æ‹Ÿ3ä¸‡å­—å¤„ç†çš„æœ€ç»ˆé˜¶æ®µ
    # å‡è®¾ç»è¿‡å¤šè½®4000 tokenså¤„ç†ï¼Œç´¯ç§¯äº†å¤§é‡ä¿¡æ¯
    final_accumulated_summary = "ç»è¿‡å¤šè½®åˆ†æï¼šæ˜¨æ™šæ£®æ—ä¼ æ¥è§„å¾‹å£°éŸ³ï¼Œè€æ©¡æ ‘é™„è¿‘å‘ç°é»‘å½±ç§»åŠ¨ã€‚å¼ ä¸‰ä¸¢å¤±æ–§å¤´ï¼Œåœ°é¢æœ‰å¤§é´å­è„šå°æ­¥ä¼æ€¥ä¿ƒã€‚é»‘å½±èº«é«˜ä¸€ç±³å…«å·¦å³ã€‚æå››æ·±å¤œå¤–å‡ºï¼Œä¸å¼ ä¸‰æœ‰çŸ›ç›¾ï¼Œèº«é«˜ç¬¦åˆã€‚ç‹äº”ä¹Ÿæœ‰å«Œç–‘ä½†æœ‰ä¸åœ¨åœºè¯æ˜ã€‚èµµå…­æ›¾å¨èƒå¼ ä¸‰ä½†èº«é«˜ä¸ç¬¦ã€‚æœ€ç»ˆè¯æ®æŒ‡å‘æå››ï¼šåŠ¨æœºæ˜ç¡®ï¼Œèº«é«˜ç¬¦åˆï¼Œæ—¶é—´åœ°ç‚¹å»åˆï¼Œä¸”æ— ä¸åœ¨åœºè¯æ˜ã€‚"

    context5 = {
        "summary_so_far": final_accumulated_summary
    }

    prompt5 = get_prompt("final", context5, model)
    total5 = len(system_prompt) + len(prompt5)

    print(f"\n--- åœºæ™¯5ï¼š3ä¸‡å­—å¤„ç†æœ€ç»ˆæ¨ç† ---")
    print(f"User prompt: '{prompt5}' ({len(prompt5)} chars)")
    print(f"Total length: {total5} chars")
    print(f"âœ… Within limit: {total5 < 200}")

    # æ±‡æ€»æŠ¥å‘Š
    print(f"\n" + "="*50)
    print(f"ğŸ“‹ Prompt Length Test Summary")
    print(f"="*50)
    print(f"System prompt length: {len(system_prompt)} chars")
    print(f"Target total limit: 360 chars")
    print(f"")
    print(f"Test results:")
    print(f"  åœºæ™¯1 (åˆå§‹æ‘˜è¦): {total1} chars - {'âœ… PASS' if total1 < 360 else 'âŒ FAIL'}")
    print(f"  åœºæ™¯2 (æ›´æ–°æ‘˜è¦): {total2} chars - {'âœ… PASS' if total2 < 360 else 'âŒ FAIL'}")
    print(f"  åœºæ™¯3 (æœ€ç»ˆæ¨ç†): {total3} chars - {'âœ… PASS' if total3 < 360 else 'âŒ FAIL'}")
    print(f"  åœºæ™¯4 (4000å­—æ€»ç»“): {total4} chars - {'âœ… PASS' if total4 < 360 else 'âŒ FAIL'}")
    print(f"  åœºæ™¯5 (3ä¸‡å­—æœ€ç»ˆ): {total5} chars - {'âœ… PASS' if total5 < 360 else 'âŒ FAIL'}")

    all_pass = all([total1 < 360, total2 < 360, total3 < 360, total4 < 360, total5 < 360])
    print(f"")
    print(f"Overall result: {'âœ… ALL TESTS PASS' if all_pass else 'âŒ SOME TESTS FAIL'}")
    
    if all_pass:
        print(f"ğŸ¯ Atlas model prompts are optimized for <360 char limit!")
        print(f"âœ… æ”¯æŒ4000å­—æ€»ç»“å¸¦å…¥ä¸‹æ¬¡å¯¹è¯")
        print(f"âœ… æ”¯æŒ3ä¸‡å­—ä»¥ä¸Šå†…å®¹å¤šè½®å¤„ç†")
        print(f"âœ… æ¯æ¬¡å¯¹è¯éƒ½åŒ…å«ä»»åŠ¡è¯´æ˜+æ¦‚æ‹¬+æ–°å†…å®¹")
        print(f"âœ… ç³»ç»Ÿæç¤ºè¯120å­—ç¬¦ï¼Œç”¨æˆ·æç¤ºè¯<240å­—ç¬¦")
    else:
        print(f"âš ï¸ Some prompts exceed the 360 character limit")

if __name__ == "__main__":
    test_prompt_lengths()
