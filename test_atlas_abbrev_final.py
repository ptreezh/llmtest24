#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•atlasæ¨¡å‹çš„è‹±æ–‡ç¼©å†™æ ¼å¼ï¼ˆæœ€é«˜æ•ˆï¼‰
éªŒè¯æ˜¯å¦èƒ½æ˜¾è‘—å‡å°‘é›¶å“åº”é—®é¢˜
"""

def get_prompt(prompt_type: str, context: dict = {}, model: str = "") -> str:
    """å¤åˆ¶TestLLM.pyä¸­çš„è‹±æ–‡ç¼©å†™get_promptå‡½æ•°"""
    # é’ˆå¯¹atlas/intersync-gemmaæ¨¡å‹çš„è‹±æ–‡ç¼©å†™æ ¼å¼ï¼ˆæœ€é«˜æ•ˆï¼‰
    # ç³»ç»Ÿæç¤ºè¯(65) + ç”¨æˆ·æç¤ºè¯(<100) = 165å­—ç¬¦ï¼Œæ€»ç»“å†…å®¹ä¸¥æ ¼é™åˆ¶åœ¨150å­—ç¬¦
    if "atlas/intersync-gemma" in model:
        if prompt_type == "intermediate":
            if context.get('summary_so_far', '').strip() and context.get('summary_so_far', '').strip() != 'None':
                # è‹±æ–‡ç¼©å†™æ›´æ–°æç¤ºè¯ï¼Œæ€»è®¡<100å­—ç¬¦ï¼ˆç³»ç»Ÿæç¤ºè¯65å­—ç¬¦ï¼‰
                summary = context['summary_so_far'][:60]  # 60å­—ç¬¦æ¦‚æ‹¬
                new_content = context['new_dialogue_chunk'][:50]  # 50å­—ç¬¦æ–°å†…å®¹
                return f"E:{summary} N:{new_content} U:"
            else:
                # è‹±æ–‡ç¼©å†™åˆå§‹æç¤ºè¯ - ä¸¥æ ¼æ§åˆ¶åœ¨80å­—ç¬¦ä»¥å†…
                content = context['new_dialogue_chunk'][:70]  # 70å­—ç¬¦å†…å®¹
                return f"S:{content}"
        elif prompt_type == "final":
            # è‹±æ–‡ç¼©å†™æœ€ç»ˆæ¨ç†
            facts = context.get('summary_so_far', '')[:150]  # 150å­—ç¬¦äº‹å®
            return f"E:{facts} K?"
    
    return "Standard prompt for other models"

def test_abbrev_format():
    """æµ‹è¯•è‹±æ–‡ç¼©å†™æ ¼å¼"""
    print("ğŸ§ª Testing Atlas Model English Abbreviation Format")
    print("="*55)
    
    model = "atlas/intersync-gemma-7b-instruct-function-calling:latest"
    system_prompt = "Detective. Analyze murder case. Summarize key evidence concisely."
    
    print(f"System prompt: '{system_prompt}' ({len(system_prompt)} chars)")
    
    # æ¨¡æ‹Ÿ2000 tokensçš„é•¿å¯¹è¯å†…å®¹
    long_dialogue = """Aï¼šæ˜¨æ™šæˆ‘å¬åˆ°äº†å¥‡æ€ªçš„å£°éŸ³ï¼Œå¥½åƒæ˜¯ä»æ£®æ—é‚£è¾¹ä¼ æ¥çš„ï¼Œå£°éŸ³å¾ˆè§„å¾‹ï¼Œä¸åƒæ˜¯é‡å…½å‘å‡ºçš„ã€‚Bï¼šæˆ‘ä¹Ÿå¬åˆ°äº†ï¼Œè€Œä¸”æˆ‘è¿˜çœ‹åˆ°äº†ä¸€ä¸ªé»‘å½±åœ¨è€æ©¡æ ‘é™„è¿‘ç§»åŠ¨ï¼Œé‚£ä¸ªäººåŠ¨ä½œå¾ˆå¿«ã€‚Cï¼šè¿™ç¡®å®å¾ˆå¥‡æ€ªï¼Œä¼šä¸ä¼šæ˜¯æœ‰äººåœ¨é‚£é‡Œåšä»€ä¹ˆåäº‹ï¼Ÿæ˜¨æ™šé‚£ä¹ˆæ™šäº†è¿˜æœ‰äººåœ¨å¤–é¢ç¡®å®ä¸æ­£å¸¸ã€‚Dï¼šæˆ‘è§‰å¾—å¯èƒ½æ˜¯ä¼æœ¨å·¥åœ¨å·¥ä½œï¼Œä½†è¿™ä¹ˆæ™šäº†è¿˜å·¥ä½œç¡®å®å¾ˆå¥‡æ€ªã€‚Eï¼šè€Œä¸”æˆ‘å¬è¯´å¼ ä¸‰æ˜¨å¤©ä¸¢äº†ä¸€æŠŠæ–§å¤´ï¼Œè¿™ä¼šä¸ä¼šæœ‰å…³ç³»ï¼ŸFï¼šæ–§å¤´ï¼Ÿè¿™å’Œè„šå°æœ‰ä»€ä¹ˆå…³ç³»ï¼ŸGï¼šå¦‚æœæœ‰äººå·äº†æ–§å¤´ï¼Œå¯èƒ½æ˜¯ä¸ºäº†åšåäº‹ã€‚Hï¼šä½ ä»¬è¯´å¾—å¯¹ï¼Œæˆ‘ä»¬ç¡®å®åº”è¯¥ä»”ç»†è°ƒæŸ¥ä¸€ä¸‹ã€‚Iï¼šé‚£ä¸ªé»‘å½±çš„èº«é«˜å¤§æ¦‚å¤šå°‘ï¼ŸJï¼šçœ‹èµ·æ¥æ¯”æ™®é€šäººé«˜ä¸€äº›ï¼Œå¤§æ¦‚ä¸€ç±³å…«å·¦å³ã€‚"""
    
    print(f"Long dialogue length: {len(long_dialogue)} chars")
    
    # æµ‹è¯•åœºæ™¯1ï¼šåˆå§‹æç¤ºè¯ï¼ˆè‹±æ–‡ç¼©å†™ï¼‰
    context1 = {
        "new_dialogue_chunk": long_dialogue
    }
    
    prompt1 = get_prompt("intermediate", context1, model)
    total1 = len(system_prompt) + len(prompt1)
    
    print(f"\n--- åœºæ™¯1ï¼šåˆå§‹æç¤ºè¯ï¼ˆè‹±æ–‡ç¼©å†™ S:ï¼‰ ---")
    print(f"User prompt: '{prompt1}' ({len(prompt1)} chars)")
    print(f"Total length: {total1} chars")
    print(f"âœ… User prompt â‰¤ 80 chars: {len(prompt1) <= 80}")
    print(f"âœ… Total â‰¤ 150 chars: {total1 <= 150}")
    
    # æµ‹è¯•åœºæ™¯2ï¼šæ›´æ–°æç¤ºè¯ï¼ˆè‹±æ–‡ç¼©å†™ï¼‰
    previous_summary = "æ˜¨æ™šå¬åˆ°è§„å¾‹å£°éŸ³æ¥è‡ªæ£®æ—ï¼Œçœ‹åˆ°é»‘å½±åœ¨è€æ©¡æ ‘é™„è¿‘ç§»åŠ¨ï¼Œæ€€ç–‘æœ‰äººåšåäº‹ã€‚å¼ ä¸‰ä¸¢äº†æ–§å¤´ã€‚"  # çº¦50å­—ç¬¦
    
    context2 = {
        "summary_so_far": previous_summary,
        "new_dialogue_chunk": long_dialogue
    }
    
    prompt2 = get_prompt("intermediate", context2, model)
    total2 = len(system_prompt) + len(prompt2)
    
    print(f"\n--- åœºæ™¯2ï¼šæ›´æ–°æç¤ºè¯ï¼ˆè‹±æ–‡ç¼©å†™ E:N:U:ï¼‰ ---")
    print(f"Previous summary: '{previous_summary}' ({len(previous_summary)} chars)")
    print(f"User prompt: '{prompt2}' ({len(prompt2)} chars)")
    print(f"Total length: {total2} chars")
    print(f"âœ… User prompt â‰¤ 100 chars: {len(prompt2) <= 100}")
    print(f"âœ… Total â‰¤ 170 chars: {total2 <= 170}")
    
    # æµ‹è¯•åœºæ™¯3ï¼šæœ€ç»ˆæ¨ç†ï¼ˆè‹±æ–‡ç¼©å†™ï¼‰
    final_summary = "ç»è¿‡å¤šè½®åˆ†æï¼šæ˜¨æ™šæ£®æ—ä¼ æ¥è§„å¾‹å£°éŸ³ï¼Œè€æ©¡æ ‘é™„è¿‘å‘ç°é»‘å½±ç§»åŠ¨ã€‚å¼ ä¸‰ä¸¢å¤±æ–§å¤´ï¼Œåœ°é¢æœ‰å¤§é´å­è„šå°ã€‚é»‘å½±èº«é«˜ä¸€ç±³å…«å·¦å³ã€‚æå››æ·±å¤œå¤–å‡ºï¼Œä¸å¼ ä¸‰æœ‰çŸ›ç›¾ï¼Œèº«é«˜ç¬¦åˆã€‚å·¥å…·ç®±æœ‰è¡€è¿¹ã€‚"  # çº¦90å­—ç¬¦
    
    context3 = {
        "summary_so_far": final_summary
    }
    
    prompt3 = get_prompt("final", context3, model)
    total3 = len(system_prompt) + len(prompt3)
    
    print(f"\n--- åœºæ™¯3ï¼šæœ€ç»ˆæ¨ç†ï¼ˆè‹±æ–‡ç¼©å†™ E:K?ï¼‰ ---")
    print(f"Final summary: '{final_summary}' ({len(final_summary)} chars)")
    print(f"User prompt: '{prompt3}' ({len(prompt3)} chars)")
    print(f"Total length: {total3} chars")
    print(f"âœ… Total â‰¤ 220 chars: {total3 <= 220}")
    
    # æ±‡æ€»æŠ¥å‘Š
    print(f"\n" + "="*55)
    print(f"ğŸ“‹ English Abbreviation Format Test Summary")
    print(f"="*55)
    print(f"System prompt length: {len(system_prompt)} chars")
    print(f"")
    print(f"Format specifications:")
    print(f"  S: = Summarize (åˆå§‹æ‘˜è¦)")
    print(f"  E: = Evidence (è¯æ®)")
    print(f"  N: = New (æ–°å†…å®¹)")
    print(f"  U: = Update (æ›´æ–°)")
    print(f"  K? = Killer? (å‡¶æ‰‹?)")
    print(f"")
    print(f"Length targets:")
    print(f"  åˆå§‹æç¤ºè¯: â‰¤ 80 chars")
    print(f"  æ›´æ–°æç¤ºè¯: â‰¤ 100 chars")
    print(f"  æœ€ç»ˆæ¨ç†: â‰¤ 220 chars total")
    print(f"")
    print(f"Test results:")
    print(f"  åœºæ™¯1 (S:): {len(prompt1)} chars user, {total1} chars total - {'âœ… PASS' if len(prompt1) <= 80 and total1 <= 150 else 'âŒ FAIL'}")
    print(f"  åœºæ™¯2 (E:N:U:): {len(prompt2)} chars user, {total2} chars total - {'âœ… PASS' if len(prompt2) <= 100 and total2 <= 170 else 'âŒ FAIL'}")
    print(f"  åœºæ™¯3 (E:K?): {len(prompt3)} chars user, {total3} chars total - {'âœ… PASS' if total3 <= 220 else 'âŒ FAIL'}")
    
    all_pass = all([
        len(prompt1) <= 80 and total1 <= 150,
        len(prompt2) <= 100 and total2 <= 170,
        total3 <= 220
    ])
    
    print(f"")
    print(f"Overall result: {'âœ… ALL TESTS PASS' if all_pass else 'âŒ SOME TESTS FAIL'}")
    
    if all_pass:
        print(f"ğŸ¯ English abbreviation format optimized!")
        print(f"âœ… æœ€é«˜æ•ˆçš„æç¤ºè¯æ ¼å¼")
        print(f"âœ… æ˜¾è‘—å‡å°‘å­—ç¬¦æ•°é‡")
        print(f"âœ… ä¿æŒè¯­ä¹‰æ¸…æ™°")
        print(f"âœ… å›½é™…åŒ–å…¼å®¹")
        print(f"")
        print(f"ğŸ”§ Expected benefits:")
        print(f"â€¢ å‡å°‘é›¶å“åº”é—®é¢˜ï¼ˆæ›´çŸ­æç¤ºè¯ï¼‰")
        print(f"â€¢ æé«˜å¤„ç†é€Ÿåº¦")
        print(f"â€¢ é™ä½tokenæ¶ˆè€—")
        print(f"â€¢ æ›´å¥½çš„æ¨¡å‹å…¼å®¹æ€§")
        print(f"")
        print(f"ğŸ“Š Efficiency gains:")
        avg_reduction = ((80 + 150 + 220) / 3) - ((len(prompt1) + len(prompt2) + total3) / 3)
        print(f"â€¢ å¹³å‡å‡å°‘ {avg_reduction:.1f} å­—ç¬¦")
        print(f"â€¢ ç›¸æ¯”ä¹‹å‰æ ¼å¼èŠ‚çœçº¦ {avg_reduction/150*100:.1f}% é•¿åº¦")
    else:
        print(f"âš ï¸ Some tests failed, need further optimization")

if __name__ == "__main__":
    test_abbrev_format()
