# LLM高级能力测评套件 v3.0 - 完整测试说明文档

## 📋 概述与目标

### 🎯 核心目标
评估大语言模型（LLM）在多轮复杂交互中的高级能力，特别是其作为"认知引擎"的潜力。核心关注点在于模型处理超长上下文、任务分解与重组、状态追踪、主动澄清以及工具协同的能力。

### 📊 评估维度
- **基础能力** (Pillars 1-8): 逻辑推理、指令遵循、结构化操作、长上下文、领域知识、工具使用、任务规划、元认知
- **高级能力** (Pillars 9-19): 创意生成、数学推理、安全伦理、角色扮演、复杂初始化、任务图谱、多智能体协作、共识达成等
- **前沿能力** (Pillars 20-24): 海量角色共识、动态角色切换、项目管理、并行任务优化、多学科分解
- **综合工作流**: 将基础与高级能力组合，模拟真实世界复杂任务场景

## 🏗️ 项目结构

### 📁 项目结构说明

#### 🎯 **两个并行的测试体系**

**1. 根目录测试体系** (完整版本)
```
testLLM/
├── tests/                              # 完整测试套件
│   ├── test_pillar_01_logic.py         # ✅ 基础测试 1-8 (已实现)
│   ├── test_pillar_02_instruction.py
│   ├── ... (test_pillar_03-08)
│   ├── test_pillar_09_creativity.py    # ✅ 高级测试 9-19 (已实现)
│   ├── ... (test_pillar_10-19)
│   ├── test_pillar_20_multidisciplinary_decomposition.py # ✅ 前沿测试 20-21
│   └── test_pillar_21_parallel_task_optimization.py
├── config.py                           # 配置文件
├── utils.py                            # 工具函数
└── main_orchestrator.py               # 主执行器
```

**2. testLLM2测试体系** (部分版本 + 扩展)
```
testLLM2/
├── tests/                              # 部分测试套件 + 新增扩展
│   ├── ❌ 缺失 test_pillar_01-08       # 基础测试缺失
│   ├── test_pillar_09_creativity.py    # ✅ 高级测试 9-19 (重新实现)
│   ├── ... (test_pillar_10-19)
│   ├── test_pillar_20_massive_consensus.py      # ✅ 新增前沿测试 20-24
│   ├── test_pillar_21_dynamic_role_switching.py
│   ├── test_pillar_22_project_management.py
│   ├── test_pillar_23_parallel_task_optimization.py
│   └── test_pillar_24_multidisciplinary_decomposition.py
├── config.py                           # 配置文件
├── user_prompts/                       # 测试用例文件
├── run_all_tests.py                    # 运行脚本
└── testout/                            # 输出目录
```

## 🧪 测试体系详解

### 📊 测试分层结构

#### 🔵 基础能力层 (Pillars 1-8) - 已完全实现
> **注意**: 这些测试在根目录的 `tests/` 中已完全实现，但在 `testLLM2/tests/` 中缺失

1. **Pillar 1: 逻辑-因果推理**
   - **测试内容**: 解决需要多步逻辑演绎和物理常识的问题
   - **示例场景**: 概率推理、抽屉原理、逻辑链推导
   - **评估标准**: 推理步骤的正确性、逻辑链的完整性

2. **Pillar 2: 指令遵循**
   - **测试内容**: 准确理解和执行复杂、多层次的指令
   - **示例场景**: 多步骤任务、条件分支指令、格式要求
   - **评估标准**: 指令理解准确性、执行完整性

3. **Pillar 3: 结构化与抽象操作**
   - **测试内容**: 处理结构化数据和抽象概念
   - **示例场景**: JSON处理、数据转换、抽象模式识别
   - **评估标准**: 结构理解能力、抽象思维水平

4. **Pillar 4: 长上下文连贯性**
   - **测试内容**: 在长对话中保持一致性和连贯性
   - **示例场景**: 多轮对话、上下文引用、信息整合
   - **评估标准**: 上下文保持能力、信息一致性

5. **Pillar 5: 应用领域知识**
   - **测试内容**: 运用专业领域知识解决问题
   - **示例场景**: 医学诊断、法律分析、技术问题
   - **评估标准**: 专业知识准确性、应用能力

6. **Pillar 6: 工具使用与代理潜力**
   - **测试内容**: 使用外部工具和API的能力
   - **示例场景**: 文件操作、API调用、工具链组合
   - **评估标准**: 工具理解能力、集成使用效果

7. **Pillar 7: 任务分解与规划**
   - **测试内容**: 将复杂任务分解为可执行步骤
   - **示例场景**: 项目规划、工作流设计、步骤排序
   - **评估标准**: 分解合理性、规划可行性

8. **Pillar 8: 元认知意识**
   - **测试内容**: 对自身能力和局限性的认知
   - **示例场景**: 能力评估、不确定性表达、学习需求识别
   - **评估标准**: 自我认知准确性、谦逊程度

#### 🟢 高级能力层 (Pillars 9-19) - 已实现
9. **Pillar 9: 创意生成与发散思维** - 创新思维和创意解决方案
10. **Pillar 10: 数学与定量推理** - 复杂数学问题和定量分析
11. **Pillar 11: 安全性与伦理判断** - 安全风险识别和伦理决策
12. **Pillar 12: 角色扮演与身份一致性** - 保持角色特征的一致性
13. **Pillar 13: 复杂指令解析与系统初始化** - 复杂系统的理解和初始化
14. **Pillar 14: 多角色协作与对话管理** - 多角色场景的协调管理
15. **Pillar 15: 共识达成与迭代改进** - 在分歧中达成共识
16. **Pillar 16: 记忆银行与状态追踪** - 长期记忆和状态管理
17. **Pillar 17: 复杂任务图谱生成** - 复杂项目的依赖关系建模
18. **Pillar 18: Agent自我反思与改进** - 自我评估和持续改进
19. **Pillar 19: 复杂推理与场景模拟** - 复杂场景的推理和模拟

#### 🔴 前沿能力层 (Pillars 20-24) - 新增前沿测试
20. **Pillar 20: 海量角色协同编辑与区块链共识** - 50-200个角色的大规模协作
21. **Pillar 21: 动态角色切换与外部记忆管理** - 角色轮流切换和状态连续性
22. **Pillar 22: 强项目管理、分工协调、状态跟踪、最终集成** - 复杂项目全流程管理
23. **Pillar 23: 复合任务分解为并行任务的能力** - 并行任务优化调度
24. **Pillar 24: 复杂综合多学科任务分解** - 跨学科知识整合

## 🚀 快速开始

### 1. 环境准备
```bash
# 安装依赖
pip install ollama

# 启动Ollama服务
ollama serve

# 下载测试模型 (示例)
ollama pull qwen2:7b
```

### 2. 配置模型
编辑 `config.py` 文件：
```python
MODEL_TO_TEST = 'qwen2:7b'  # 替换为您的模型
```

### 3. 运行测试

#### 🔵 运行高级能力测试 (Pillar 9-19)
```bash
python run_all_tests.py
```

#### 🔴 运行前沿能力测试 (Pillar 20-24)
```bash
python run_advanced_capability_tests.py
```

#### 🎯 运行特定测试
```bash
# 海量角色共识测试
python run_massive_consensus_test.py

# 动态角色切换测试
python run_dynamic_role_switching_test.py

# 单独运行某个测试
python tests/test_pillar_17_dag_generation.py
```

### 4. 查看结果
```bash
# 查看测试输出
ls testout/

# 运行分析脚本
python analyze_results.py
```

## 🎯 重点测试推荐

### 🔥 最具挑战性的测试
1. **Pillar 20**: 海量角色共识 - 测试100+角色的协作能力
2. **Pillar 21**: 动态角色切换 - 测试外部记忆管理能力
3. **Pillar 22**: 项目管理集成 - 测试复杂项目全流程管理
4. **Pillar 23**: 并行任务优化 - 测试并行化思维能力
5. **Pillar 24**: 多学科分解 - 测试跨学科知识整合

### 📊 推荐测试顺序

#### 🎯 针对不同评估目标的建议

**完整能力评估**:
1. 运行 Pillar 9-19 (基础高级能力验证)
2. 运行 Pillar 20-24 (前沿能力挑战)
3. 分析结果，识别强项和弱项

**快速能力验证**:
1. Pillar 12 (角色扮演) + Pillar 17 (任务图谱)
2. Pillar 20 (海量协作) + Pillar 21 (动态切换)
3. 基于结果决定是否进行完整测试

**特定能力深度测试**:
- **项目管理能力**: Pillar 15 + 17 + 22
- **协作能力**: Pillar 14 + 20 + 21  
- **任务分解能力**: Pillar 17 + 23 + 24

## 💡 测试特色与创新

### 🌟 独特测试设计

#### **Pillar 20 - 海量角色共识**
- ✅ 真实的50-200个角色协作场景
- ✅ 区块链共识算法的理解和应用
- ✅ 大规模投票机制和权重分配
- ✅ 复杂分歧的识别和解决

#### **Pillar 21 - 动态角色切换**
- ✅ 真实的外部文件读写操作
- ✅ 角色特定的记忆文件管理
- ✅ 跨会话的状态连续性测试
- ✅ 多源信息的整合能力

#### **Pillar 22 - 项目管理集成**
- ✅ 复杂项目的状态图建模
- ✅ 多团队协调和资源分配
- ✅ 风险管理和应急响应
- ✅ 最终成果的集成验证

#### **Pillar 23 - 并行任务优化**
- ✅ 复杂依赖关系的分析
- ✅ 资源冲突的识别和解决
- ✅ 关键路径的优化策略
- ✅ 并行度的最大化利用

#### **Pillar 24 - 多学科分解**
- ✅ 6-7个学科的知识融合
- ✅ 跨学科创新机会识别
- ✅ 全球协调机制设计
- ✅ 复杂系统的层次化分解

## 📈 结果分析与评估

### 🎯 评估维度

#### 定量指标
- **成功率**: 测试完成的成功比例
- **响应质量**: 回答的准确性和完整性
- **处理时间**: 复杂任务的处理效率
- **一致性**: 多轮对话中的表现稳定性

#### 定性指标
- **创新性**: 解决方案的创新程度
- **实用性**: 方案的可操作性
- **系统性**: 思考的系统化程度
- **适应性**: 对变化的适应能力

### 📊 分析工具

#### 自动化分析
```bash
# 基础结果分析
python analyze_results.py

# 专项能力分析
python analyze_massive_consensus.py
python analyze_dynamic_role_switching.py
```

#### 手动分析
- 查看 `testout/` 目录中的详细JSON结果
- 对比不同模型的表现差异
- 识别特定能力的强项和弱项

## ⚠️ 注意事项

### 🔧 技术要求
- **计算资源**: 前沿测试需要较多计算资源
- **时间成本**: 完整测试可能需要30-60分钟
- **模型兼容**: 确保模型支持长上下文处理
- **网络稳定**: 确保Ollama服务稳定运行

### 📋 使用建议
1. **渐进式测试**: 从简单测试开始，逐步增加复杂度
2. **结果对比**: 在相同环境下测试不同模型进行对比
3. **多次运行**: 对关键测试进行多次运行以确保稳定性
4. **详细记录**: 保存测试环境和参数设置以便复现

### 🔍 故障排除
- **连接失败**: 检查Ollama服务是否启动
- **模型错误**: 确认模型名称正确且已下载
- **编码问题**: 确保系统支持UTF-8编码
- **内存不足**: 考虑减少并发测试数量

## 📚 测试用例详解

### 🎯 核心测试场景

#### **Pillar 20: 海量角色共识测试**
- **用例1**: 20个角色协作编辑"人工智能伦理"词条，使用多数决投票
- **用例2**: 50个角色协作编辑"量子计算"词条，使用权威加权投票
- **用例3**: 100个角色协作编辑"元宇宙技术"词条，使用拜占庭容错共识

#### **Pillar 21: 动态角色切换测试**
- **角色设定**: 侦探李明、王医生、张老师三个角色轮流切换
- **测试流程**: 角色切换序列 → 记忆持续性 → 注意力焦点维护
- **关键验证**: 外部记忆文件读写、状态连续性、信息隔离

#### **Pillar 22: 项目管理集成测试**
- **场景1**: ERP系统集成项目 (35人团队，18个月，2000万预算)
- **场景2**: 多地点酒店建设 (5个城市同步，150人团队)
- **场景3**: 智能手表全球发布 (15国同步，200人团队)

#### **Pillar 23: 并行任务优化测试**
- **场景1**: 数据中心迁移 (500台服务器，32人团队，3个月)
- **场景2**: 微服务架构重构 (30个服务，61人团队，6个月)
- **场景3**: 汽车生产线建设 (多条生产线，8个月工期)

#### **Pillar 24: 多学科分解测试**
- **场景1**: 智慧城市转型 (6大学科，800万人口，5000亿投资)
- **场景2**: 全球气候变化应对 (6大学科，195国协调，25年时间)
- **场景3**: 太空探索百年计划 (7大学科，跨代项目，万亿投资)

## 🔧 技术实现细节

### 📋 配置文件说明

#### config.py 关键配置
```python
# 模型配置
MODEL_TO_TEST = 'qwen2:7b'  # 主要测试模型
OLLAMA_HOST = 'http://localhost:11434'  # Ollama服务地址

# 测试选项
DEFAULT_OPTIONS_DETERMINISTIC = {'temperature': 0.0}  # 确定性任务
DEFAULT_OPTIONS_CREATIVE = {'temperature': 0.7}      # 创造性任务

# 目录配置
TEST_WORKSPACE_DIR = 'test_workspace'  # 测试工作目录
LOG_DIR = 'test_logs'                  # 日志目录
REPORT_DIR = 'test_reports'            # 报告目录
```

### 🛠️ 核心工具函数

#### utils.py 主要功能
- **run_single_test()**: 执行单次测试的核心函数
- **print_assessment_criteria()**: 格式化打印评估标准
- **setup_test_environment()**: 创建测试环境
- **save_file() / read_file()**: 文件操作工具
- **execute_bash_script()**: 脚本执行工具

### 📊 测试结果格式

#### JSON输出结构
```json
{
  "test_name": "pillar_20_massive_consensus",
  "model": "qwen2:7b",
  "timestamp": 1703123456.789,
  "parameters": {
    "num_roles": 50,
    "topic": "量子计算",
    "consensus_algorithm": "权威加权投票"
  },
  "results": {
    "role_generation": {...},
    "collaborative_editing": {...},
    "voting_mechanism": {...},
    "blockchain_consensus": {...}
  },
  "analysis": {
    "success_rate": 0.85,
    "quality_score": 0.78,
    "recommendations": [...]
  }
}
```

## 🎓 使用最佳实践

### 📈 测试策略建议

#### 🎯 针对不同目标的测试组合

**模型能力全面评估**:
```bash
# 第一阶段：基础能力验证
python tests/test_pillar_12_persona.py
python tests/test_pillar_15_collaboration.py
python tests/test_pillar_17_dag_generation.py

# 第二阶段：高级能力挑战
python run_advanced_capability_tests.py

# 第三阶段：结果分析
python analyze_results.py
```

**特定能力深度测试**:
```bash
# 协作能力专项测试
python tests/test_pillar_14_persona_depth.py
python tests/test_pillar_20_massive_consensus.py
python tests/test_pillar_21_dynamic_role_switching.py

# 项目管理能力专项测试
python tests/test_pillar_15_collaboration.py
python tests/test_pillar_22_project_management.py
python tests/test_pillar_23_parallel_task_optimization.py
```

### ⚡ 性能优化建议

#### 🔧 系统配置优化
- **内存配置**: 建议16GB+内存用于大规模测试
- **并发控制**: 避免同时运行多个重型测试
- **网络稳定**: 确保Ollama服务稳定连接
- **存储空间**: 预留足够空间存储测试结果

#### 📊 测试效率提升
- **分批测试**: 将大型测试分解为小批次
- **结果缓存**: 避免重复运行相同配置的测试
- **日志管理**: 定期清理旧的测试日志
- **错误恢复**: 实现测试失败的自动重试机制

## 🔍 故障排除指南

### ❗ 常见问题及解决方案

#### 连接问题
```bash
# 检查Ollama服务状态
ollama list

# 重启Ollama服务
ollama serve

# 检查端口占用
netstat -an | grep 11434
```

#### 模型问题
```bash
# 检查已安装模型
ollama list

# 下载缺失模型
ollama pull qwen2:7b

# 验证模型可用性
ollama run qwen2:7b "Hello"
```

#### 权限问题
```bash
# 检查文件权限
ls -la testout/

# 修复权限问题
chmod -R 755 testout/
chmod -R 755 tests/
```

#### 编码问题
```python
# 在Python脚本中设置编码
import sys
sys.stdout.reconfigure(encoding='utf-8')
```

### 🐛 调试技巧

#### 详细日志启用
```python
# 在config.py中添加调试配置
DEBUG_MODE = True
VERBOSE_LOGGING = True
```

#### 单步调试
```bash
# 运行单个测试进行调试
python tests/test_pillar_20_massive_consensus.py

# 查看详细输出
python tests/test_pillar_21_dynamic_role_switching.py --verbose
```

## 🔮 未来发展

### 📈 计划增强
1. **基础测试实现**: 完成Pillar 1-8的实现
2. **更多前沿测试**: 继续添加新的前沿能力测试
3. **自动化分析**: 增强结果分析的自动化程度
4. **可视化报告**: 提供更直观的测试结果展示

### 🌟 创新方向
- **多模态测试**: 支持图像、音频等多模态输入
- **实时交互**: 支持实时对话和动态调整
- **分布式测试**: 支持大规模分布式测试环境
- **标准化评估**: 建立行业标准的评估体系

### 🤝 社区贡献
- **测试用例贡献**: 欢迎提交新的测试场景
- **分析工具改进**: 优化结果分析和可视化
- **文档完善**: 改进使用说明和最佳实践
- **Bug修复**: 报告和修复发现的问题

---

**版本**: v3.0
**更新日期**: 2024年12月
**兼容性**: 支持所有主流LLM模型
**许可**: 开源项目，欢迎贡献和改进
**联系方式**: 通过GitHub Issues提交问题和建议
